<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>brian abelson - OpenNews</title>
		<description>Posts categorized as 'open-news'</description>
		<link>http://brianabelson.com</link>
		<atom:link href="http://brianabelson.com/feed.category.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Scrape the Gibson: Python skills for data scrapers</title>
				<description>&lt;p&gt;&lt;em&gt;Most of the code in this post is based on &lt;a href='https://github.com/pudo/hhba-scraping'&gt;a workshop&lt;/a&gt; my fellow ex-OpenNews fellow &lt;a href='http://www.twitter.com/pudo'&gt;@pudo&lt;/a&gt; gave at &lt;a href='http://www.mediaparty.info'&gt;Hacks Hackers Buenos Aires Media Party&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;Two years ago, I learned I had superpowers. &lt;a href='http://www.twitter.com/spatiality'&gt;Steve Romalewski&lt;/a&gt; was working on some &lt;a href='http://spatialityblog.com/2011/09/29/spatial-analysis-of-nyc-bikeshare-maps/'&gt;fascinating&lt;/a&gt; &lt;a href='http://spatialityblog.com/2012/05/14/citibikenyc_firstlastmile_quantified/'&gt;analyses&lt;/a&gt; of CitiBike locations and needed some help scraping information from the city&amp;#8217;s data portal. Cobbling together the little I knew about &lt;code&gt;R&lt;/code&gt;, I wrote &lt;a href='https://gist.github.com/abelsonlive/2690803'&gt;a simple scraper&lt;/a&gt; to fetch the json files for each bike share location and output it as a csv. When I opened the clean data in Excel, the feeling was tantamount to this scene from &lt;em&gt;Hackers&lt;/em&gt;:&lt;/p&gt;
&lt;br /&gt;&lt;iframe height='360' src='//www.youtube.com/embed/vYNnPx8fZBs' width='640'&gt;
&lt;/iframe&gt;&lt;br /&gt;&lt;br /&gt;
&lt;p&gt;Ever since then I&amp;#8217;ve spent a good portion of my life scraping data from websites. From &lt;a href='http://www.imdb.com/'&gt;movies&lt;/a&gt;, to &lt;a href='http://macaulaylibrary.org/'&gt;bird sounds&lt;/a&gt;, to &lt;a href='http://newyork.craigslist.org/mis/index.html'&gt;missed connections&lt;/a&gt;, and &lt;a href='http://eccie.net'&gt;john boards&lt;/a&gt; (don&amp;#8217;t ask, I promise it&amp;#8217;s for good!), there&amp;#8217;s not much I haven&amp;#8217;t tried to scrape. In many cases, I dont&amp;#8217;t even analyze the data I&amp;#8217;ve obtained, and the whole process amounts to a nerdy version of sport hunting, with my comma-delimited trophies mounted proudly on Amazon S3.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;In this time, I&amp;#8217;ve learned a lot about what not to do when scraping websites. This trial-and-error process has involved, among other fiascos, having my office&amp;#8217;s IP address permanently banned from IMDB. At one point, I got so frustrated with &lt;code&gt;R&lt;/code&gt;&amp;#8217;s error handling that I just wrote &lt;a href='https://github.com/abelsonlive/scraply'&gt;my own library&lt;/a&gt; to do it. In the past year, however, I&amp;#8217;ve started using &lt;code&gt;python&lt;/code&gt; for scraping, and have learned a tremendous amount from my fellow ex-OpenNews Fellow &lt;a href='http://twitter.com/pudo'&gt;Friedrich Lindenberg&lt;/a&gt;. In this post I hope to share some of this knowledge.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id='basics'&gt;Basics&lt;/h2&gt;

&lt;p&gt;There are many amazing libraries for parsing HTML in python – &lt;a href='https://github.com/gawel/pyquery'&gt;pyquery&lt;/a&gt;, &lt;a href='http://scrapy.org/'&gt;scrapy&lt;/a&gt;, and &lt;a href='http://pythonhosted.org/cssselect/'&gt;cssselect&lt;/a&gt; to name a few – but I&amp;#8217;ve always preferred &lt;a href='http://www.crummy.com/software/BeautifulSoup/bs4/doc/'&gt;BeautifulSoup&lt;/a&gt; for it&amp;#8217;s deceptive simplicity. Below, we&amp;#8217;ll walk through a simple example of scraping missed connections from CraigsList. As I further develop and refine this code, I&amp;#8217;ll introduce some best practices I&amp;#8217;ve learned from &lt;a href='http://twitter.com/pudo'&gt;@pudo&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;Let&amp;#8217;s go through a simple example of retrieving missed connections from craigslist. To run the code on your computer you&amp;#8217;ll need to have four python modules installed: requests, BeautifulSoup, dataset, and thready. To install these, you can run this command in your terminal:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;sudo pip install beautifulsoup4 requests dataset thready
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If this returns and error, try installing pip and running the command again:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;sudo easy_install pip
sudo pip install beautifulsoup4 requests dataset thready
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If everything works you should be able to open a python terminal and import the libraries with no errors:&lt;/p&gt;
&lt;br /&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='pycon'&gt;&lt;span class='go'&gt;python&lt;/span&gt;
&lt;span class='gp'&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='nn'&gt;requests&lt;/span&gt;
&lt;span class='gp'&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class='kn'&gt;from&lt;/span&gt; &lt;span class='nn'&gt;bs4&lt;/span&gt; &lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='n'&gt;BeautifulSoup&lt;/span&gt;
&lt;span class='gp'&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='nn'&gt;dataset&lt;/span&gt;
&lt;span class='gp'&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class='kn'&gt;from&lt;/span&gt; &lt;span class='nn'&gt;thready&lt;/span&gt; &lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='n'&gt;threaded&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br /&gt;
&lt;p&gt;Alright, now that we&amp;#8217;re ready to get started, let&amp;#8217;s walk through a basic scraper for CraigsList missed connections. In the code snippet below I add detailed comments that explain what I&amp;#8217;m doing for each line. You can follow along with each of these scripts on &lt;a href='https://github.com/abelsonlive/scrape-the-gibson'&gt;this github repository&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;h4 id='00basicspy'&gt;00-basics.py&lt;/h4&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='python'&gt;&lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='nn'&gt;requests&lt;/span&gt;
&lt;span class='kn'&gt;from&lt;/span&gt; &lt;span class='nn'&gt;bs4&lt;/span&gt; &lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='n'&gt;BeautifulSoup&lt;/span&gt;
&lt;span class='kn'&gt;from&lt;/span&gt; &lt;span class='nn'&gt;pprint&lt;/span&gt; &lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='n'&gt;pprint&lt;/span&gt;
&lt;span class='kn'&gt;from&lt;/span&gt; &lt;span class='nn'&gt;urlparse&lt;/span&gt; &lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='n'&gt;urljoin&lt;/span&gt;

&lt;span class='c'&gt;# The base url for craigslist in New York&lt;/span&gt;
&lt;span class='n'&gt;BASE_URL&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='s'&gt;&amp;#39;http://newyork.craigslist.org/&amp;#39;&lt;/span&gt;

&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;scrape_missed_connections&lt;/span&gt;&lt;span class='p'&gt;():&lt;/span&gt;
    &lt;span class='sd'&gt;&amp;quot;&amp;quot;&amp;quot; Scrape all the missed connections from a list &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    
    &lt;span class='c'&gt;# Download the list of missed connections&lt;/span&gt;

    &lt;span class='c'&gt;# here were using requests, &lt;/span&gt;
    &lt;span class='c'&gt;# a python library for accessing the web&lt;/span&gt;

    &lt;span class='c'&gt;# we add &amp;quot;mis/&amp;quot; to the url to tell requests&lt;/span&gt;
    &lt;span class='c'&gt;# to get the missed connections &lt;/span&gt;
    &lt;span class='c'&gt;# on newyork.craigslist.org&lt;/span&gt;

    &lt;span class='n'&gt;response&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;requests&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;get&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;BASE_URL&lt;/span&gt; &lt;span class='o'&gt;+&lt;/span&gt; &lt;span class='s'&gt;&amp;quot;mis/&amp;quot;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

    &lt;span class='c'&gt;# parse HTML using Beautiful Soup&lt;/span&gt;
    &lt;span class='c'&gt;# this returns a `soup` object which&lt;/span&gt;
    &lt;span class='c'&gt;# gives us convenience methods for parsing html&lt;/span&gt;

    &lt;span class='n'&gt;soup&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;BeautifulSoup&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;response&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;content&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

    &lt;span class='c'&gt;# find all the posts in the page.&lt;/span&gt;

    &lt;span class='c'&gt;# here we&amp;#39;re telling BeautifulSoup to get us every&lt;/span&gt;
    &lt;span class='c'&gt;# span tag that has a class that equals pl&lt;/span&gt;

    &lt;span class='c'&gt;# these tags might look something like this:&lt;/span&gt;
    &lt;span class='c'&gt;# &amp;lt;span class=&amp;#39;pl&amp;#39;&amp;gt; {content} &amp;lt;/span&amp;gt;&lt;/span&gt;

    &lt;span class='n'&gt;missed_connections&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;soup&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;find_all&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;span&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;pl&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;})&lt;/span&gt;

    &lt;span class='c'&gt;# Get all the links to missed connection pages:&lt;/span&gt;
    &lt;span class='k'&gt;for&lt;/span&gt; &lt;span class='n'&gt;missed_connection&lt;/span&gt; &lt;span class='ow'&gt;in&lt;/span&gt; &lt;span class='n'&gt;missed_connections&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;
        
        &lt;span class='c'&gt;# for each span list, find the &amp;quot;a&amp;quot; tag which &lt;/span&gt;
        &lt;span class='c'&gt;# represents the link to the missed connection page.&lt;/span&gt;

        &lt;span class='n'&gt;link&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;missed_connection&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;find&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;attrs&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt;
        
        &lt;span class='c'&gt;# join this relative link with the &lt;/span&gt;
        &lt;span class='c'&gt;# BASE_URL to create an absolute link&lt;/span&gt;

        &lt;span class='n'&gt;url&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;urljoin&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;BASE_URL&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;link&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
        
        &lt;span class='c'&gt;# pass this url to a function (defined below) to scrape &lt;/span&gt;
        &lt;span class='c'&gt;# info about that missed connection&lt;/span&gt;

        &lt;span class='n'&gt;scrape_missed_connection&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;scrape_missed_connection&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;):&lt;/span&gt;
    &lt;span class='sd'&gt;&amp;quot;&amp;quot;&amp;quot; Extract information from a missed connections&amp;#39;s page. &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class='c'&gt;# retrieve the missed connection with requests&lt;/span&gt;

    &lt;span class='n'&gt;response&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;requests&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;get&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

    &lt;span class='c'&gt;# Parse the html of the missed connection post&lt;/span&gt;

    &lt;span class='n'&gt;soup&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;BeautifulSoup&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;response&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;content&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

    &lt;span class='c'&gt;# Extract the actual contents of some HTML elements:&lt;/span&gt;

    &lt;span class='c'&gt;# here were using BeautifulSoup&amp;#39;s `text` method for retrieving&lt;/span&gt;
    &lt;span class='c'&gt;# the plain text within each HTML element.&lt;/span&gt;

    &lt;span class='c'&gt;# see and example of what this page looks like here:&lt;/span&gt;

    &lt;span class='n'&gt;data&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;
        &lt;span class='s'&gt;&amp;#39;source_url&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt; &lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt;
        &lt;span class='s'&gt;&amp;#39;subject&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt; &lt;span class='n'&gt;soup&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;find&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;h2&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;postingtitle&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;})&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;text&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;strip&lt;/span&gt;&lt;span class='p'&gt;(),&lt;/span&gt;
        &lt;span class='s'&gt;&amp;#39;body&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt; &lt;span class='n'&gt;soup&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;find&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;section&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;id&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;postingbody&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;})&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;text&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;strip&lt;/span&gt;&lt;span class='p'&gt;(),&lt;/span&gt;
        &lt;span class='s'&gt;&amp;#39;datetime&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt; &lt;span class='n'&gt;soup&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;find&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;time&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;attrs&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;datetime&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt;
    &lt;span class='p'&gt;}&lt;/span&gt;

    &lt;span class='c'&gt;# Print it prettily. &lt;/span&gt;
    &lt;span class='n'&gt;pprint&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;data&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

&lt;span class='k'&gt;if&lt;/span&gt; &lt;span class='n'&gt;__name__&lt;/span&gt; &lt;span class='o'&gt;==&lt;/span&gt; &lt;span class='s'&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;
    &lt;span class='n'&gt;scrape_missed_connections&lt;/span&gt;&lt;span class='p'&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br /&gt;
&lt;p&gt;If all goes well you should see a series of python dictionaries printed to your console:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='pycon'&gt;&lt;span class='go'&gt;{&lt;/span&gt;
&lt;span class='go'&gt;    &amp;#39;body&amp;#39;: &amp;#39;I saw you on your way home from work last night. I hoped to see you on the way to work this morning, and I did. Actually, I usually see you on the way to work. I wanted to say hello this morning, and I stupidly smiled at you wanting you to smile back. You looked at me in acknowledgement but that seemed about it. I will have to talk to you the next time I see you and tell you how cute you look in that hat you were wearing.&amp;#39;,&lt;/span&gt;
&lt;span class='go'&gt;    &amp;#39;datetime&amp;#39;: &amp;#39;2013-12-18T10:50:29-0500&amp;#39;,&lt;/span&gt;
&lt;span class='go'&gt;    &amp;#39;source_url&amp;#39;: &amp;#39;http://newyork.craigslist.org/brk/mis/4249329594.html&amp;#39;,&lt;/span&gt;
&lt;span class='go'&gt;    &amp;#39;subject&amp;#39;: &amp;#39;A train to work this morning - m4w&amp;#39;&lt;/span&gt;
&lt;span class='go'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br /&gt;
&lt;h2 id='databases'&gt;Databases&lt;/h2&gt;

&lt;p&gt;We could stop here and probably be fine, but it&amp;#8217;s usually a better idea to save the data you scrape into a database. This way, if the script breaks midway through execution, we can retain the information we scraped up until that point. In addition, by using a database, we can also quickly construct an API or app on top of the data we scrape. Luckily, &lt;a href='http://www.twitter.com/'&gt;@pudo&lt;/a&gt; wrote an amazing python library called &lt;a href='http://dataset.readthedocs.org'&gt;dataset&lt;/a&gt; that makes writing to a database as easy as writing json to a file. To incorporate it into our script, we only need to change three lines:&lt;/p&gt;
&lt;br /&gt;
&lt;h4 id='01datasetpy'&gt;&lt;a href='https://github.com/abelsonlive/scrape-the-gibson/blob/master/01-dataset.py'&gt;01-dataset.py&lt;/a&gt;&lt;/h4&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='python'&gt;&lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='nn'&gt;dataset&lt;/span&gt;

&lt;span class='c'&gt;# connect to a database&lt;/span&gt;

&lt;span class='c'&gt;# here we&amp;#39;re just going to use sqlite3 which is a lightweight&lt;/span&gt;
&lt;span class='c'&gt;# SQL store, ideal for most simple scraping jobs.  However, we could&lt;/span&gt;
&lt;span class='c'&gt;# easily use MySQL or PostgreSQL by simply swapping out the path&lt;/span&gt;
&lt;span class='c'&gt;# to the database:&lt;/span&gt;

&lt;span class='n'&gt;db&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;dataset&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;connect&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;sqlite:///missed_connections.db&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

&lt;span class='o'&gt;...&lt;/span&gt;

&lt;span class='c'&gt;# now instead of simply printing our data to the console,&lt;/span&gt;
&lt;span class='c'&gt;# lets put it into our database&lt;/span&gt;

&lt;span class='c'&gt;# here db[&amp;#39;posts&amp;#39;] signifies that we are going to insert data&lt;/span&gt;
&lt;span class='c'&gt;# into the &amp;#39;posts&amp;#39; table of the database. We&amp;#39;ll use &amp;quot;upsert&amp;quot;&lt;/span&gt;
&lt;span class='c'&gt;# instead of &amp;quot;insert&amp;quot; because we&amp;#39;ll probably want to run the&lt;/span&gt;
&lt;span class='c'&gt;# scraper a few times to test it, and this way we won&amp;#39;t continually&lt;/span&gt;
&lt;span class='c'&gt;# add duplicate records to our database.&lt;/span&gt;

&lt;span class='n'&gt;db&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;posts&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;upsert&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;data&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;source_url&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Putting it all together, our new script should look something like &lt;a href='https://github.com/abelsonlive/scrape-the-gibson/blob/master/01-dataset.py'&gt;this&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id='caching'&gt;Caching&lt;/h2&gt;

&lt;p&gt;One of the most common scraping problems is realizing your script is buggy midway through execution and having to start over from scratch. This isn&amp;#8217;t too big of a problem if you&amp;#8217;re scraping a few pages, but if you&amp;#8217;re trying to pull in everything from IMDB or CraigsList, you&amp;#8217;ll slowly drive yourself insane when, three hours into a big job, you realize you forgot to grab an important piece of data. One easy way to deal with this problem is to cache the html files that you&amp;#8217;re scraping (in other words, save them to a local file).&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;To implement this, we need to write a function that checks whether we&amp;#8217;ve already saved a local version of the page already and, if so, load the cached version rather than hitting the site&amp;#8217;s server again. If not, we&amp;#8217;ll proceed as normal and request the page from the site&amp;#8217;s server and then save a version of it locally:&lt;/p&gt;
&lt;br /&gt;
&lt;h4 id='02cachingpy'&gt;02-caching.py&lt;/h4&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='python'&gt;&lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='nn'&gt;os&lt;/span&gt;
&lt;span class='kn'&gt;from&lt;/span&gt; &lt;span class='nn'&gt;hashlib&lt;/span&gt; &lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='n'&gt;sha1&lt;/span&gt;


&lt;span class='c'&gt;# a directory for caching file&amp;#39;s we&amp;#39;ve already downloaded&lt;/span&gt;
&lt;span class='n'&gt;CACHE_DIR&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;os&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;path&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;join&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;os&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;path&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;dirname&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;__file__&lt;/span&gt;&lt;span class='p'&gt;),&lt;/span&gt; &lt;span class='s'&gt;&amp;#39;cache&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;url_to_filename&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;):&lt;/span&gt;
    &lt;span class='sd'&gt;&amp;quot;&amp;quot;&amp;quot; Make a URL into a file name, using SHA1 hashes. &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class='c'&gt;# use a sha1 hash to convert the url into a unique filename&lt;/span&gt;
    &lt;span class='n'&gt;hash_file&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;sha1&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;hexdigest&lt;/span&gt;&lt;span class='p'&gt;()&lt;/span&gt; &lt;span class='o'&gt;+&lt;/span&gt; &lt;span class='s'&gt;&amp;#39;.html&amp;#39;&lt;/span&gt;
    &lt;span class='k'&gt;return&lt;/span&gt; &lt;span class='n'&gt;os&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;path&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;join&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;CACHE_DIR&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;hash_file&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;


&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;store_local&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;content&lt;/span&gt;&lt;span class='p'&gt;):&lt;/span&gt;
    &lt;span class='sd'&gt;&amp;quot;&amp;quot;&amp;quot; Save a local copy of the file. &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class='c'&gt;# If the cache directory does not exist, make one.&lt;/span&gt;
    &lt;span class='k'&gt;if&lt;/span&gt; &lt;span class='ow'&gt;not&lt;/span&gt; &lt;span class='n'&gt;os&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;path&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;isdir&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;CACHE_DIR&lt;/span&gt;&lt;span class='p'&gt;):&lt;/span&gt;
        &lt;span class='n'&gt;os&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;makedirs&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;CACHE_DIR&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;

    &lt;span class='c'&gt;# Save to disk.&lt;/span&gt;
    &lt;span class='n'&gt;local_path&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;url_to_filename&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
    &lt;span class='k'&gt;with&lt;/span&gt; &lt;span class='nb'&gt;open&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;local_path&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='s'&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt; &lt;span class='k'&gt;as&lt;/span&gt; &lt;span class='n'&gt;f&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;
        &lt;span class='n'&gt;f&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;write&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;content&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;


&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;load_local&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;):&lt;/span&gt;
    &lt;span class='sd'&gt;&amp;quot;&amp;quot;&amp;quot; Read a local copy of a URL. &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class='n'&gt;local_path&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;url_to_filename&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
    &lt;span class='k'&gt;if&lt;/span&gt; &lt;span class='ow'&gt;not&lt;/span&gt; &lt;span class='n'&gt;os&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;path&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;exists&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;local_path&lt;/span&gt;&lt;span class='p'&gt;):&lt;/span&gt;
        &lt;span class='k'&gt;return&lt;/span&gt; &lt;span class='bp'&gt;None&lt;/span&gt;

    &lt;span class='k'&gt;with&lt;/span&gt; &lt;span class='nb'&gt;open&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;local_path&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='s'&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt; &lt;span class='k'&gt;as&lt;/span&gt; &lt;span class='n'&gt;f&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;
        &lt;span class='k'&gt;return&lt;/span&gt; &lt;span class='n'&gt;f&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;read&lt;/span&gt;&lt;span class='p'&gt;()&lt;/span&gt;


&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;get_content&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;):&lt;/span&gt;
    &lt;span class='sd'&gt;&amp;quot;&amp;quot;&amp;quot; Wrap requests.get() &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class='n'&gt;content&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;load_local&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
    &lt;span class='k'&gt;if&lt;/span&gt; &lt;span class='n'&gt;content&lt;/span&gt; &lt;span class='ow'&gt;is&lt;/span&gt; &lt;span class='bp'&gt;None&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;
        &lt;span class='n'&gt;response&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;requests&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;get&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
        &lt;span class='n'&gt;content&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;response&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;content&lt;/span&gt;
        &lt;span class='n'&gt;store_local&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;content&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
    &lt;span class='k'&gt;return&lt;/span&gt; &lt;span class='n'&gt;content&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br /&gt;
&lt;p&gt;Now, everytime we request a new missed connection, we should use our &lt;code&gt;get_content&lt;/code&gt; function instead of &lt;code&gt;requests.get()&lt;/code&gt;. Merging this code in, our script should now look &lt;a href='https://github.com/abelsonlive/scrape-the-gibson/blob/master/02-caching.py'&gt;this&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id='multithreading'&gt;Multithreading&lt;/h2&gt;

&lt;p&gt;Up to this point, our script has only been capable of downloading a single missed connection at a time. It turns out that a single processor is capable of executing multiple tasks at a time via something called &amp;#8221;&lt;a href='http://en.wikipedia.org/wiki/Multithreading_(computer_architecture'&gt;multithreading&lt;/a&gt;).&amp;#8221; This is different than &lt;a href='http://en.wikipedia.org/wiki/Parallel_processing'&gt;parallel processing&lt;/a&gt; where a set of tasks are executed across across a series of networked computers. In the case of our task – scraping multiple missed connections – this means that instead of simply looping through the list of each missed connection, that we&amp;#8217;ll first detect all the urls to the missed connection pages and then download and parse these pages utilizing multiple threads within a single processor. It turns out that, once again, &lt;a href='http://twitter.com/pudo'&gt;@pudo&lt;/a&gt; has solved this problem for us. With a simple module he wrote named &lt;a href='https://github.com/pudo/thready'&gt;thready&lt;/a&gt;, we can pass this list of urls to our function that scrapes each missed connection and very quickly and easily increase the speed with which we parse all the pages. This is implemented by modifying our &lt;code&gt;scrape_missed_connections&lt;/code&gt; function as follows:&lt;/p&gt;
&lt;br /&gt;
&lt;h4 id='03multithreadingpy'&gt;03-multithreading.py&lt;/h4&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='python'&gt;&lt;span class='kn'&gt;from&lt;/span&gt; &lt;span class='nn'&gt;thready&lt;/span&gt; &lt;span class='kn'&gt;import&lt;/span&gt; &lt;span class='n'&gt;threaded&lt;/span&gt;

&lt;span class='o'&gt;...&lt;/span&gt;

&lt;span class='k'&gt;def&lt;/span&gt; &lt;span class='nf'&gt;scrape_missed_connections&lt;/span&gt;&lt;span class='p'&gt;():&lt;/span&gt;
    &lt;span class='sd'&gt;&amp;quot;&amp;quot;&amp;quot; Scrape all the missed connections from a list &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class='n'&gt;response&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;requests&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;get&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;BASE_URL&lt;/span&gt; &lt;span class='o'&gt;+&lt;/span&gt; &lt;span class='s'&gt;&amp;quot;mis/&amp;quot;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
    &lt;span class='n'&gt;soup&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;BeautifulSoup&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;response&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;content&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
    &lt;span class='n'&gt;missed_connections&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;soup&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;find_all&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;span&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='p'&gt;{&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;pl&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;})&lt;/span&gt;

    &lt;span class='c'&gt;# create an empty list of urls to scrape &lt;/span&gt;
    &lt;span class='n'&gt;urls&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='p'&gt;[]&lt;/span&gt;
    &lt;span class='k'&gt;for&lt;/span&gt; &lt;span class='n'&gt;missed_connection&lt;/span&gt; &lt;span class='ow'&gt;in&lt;/span&gt; &lt;span class='n'&gt;missed_connections&lt;/span&gt;&lt;span class='p'&gt;:&lt;/span&gt;

        &lt;span class='n'&gt;link&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;missed_connection&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;find&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;attrs&lt;/span&gt;&lt;span class='p'&gt;[&lt;/span&gt;&lt;span class='s'&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class='p'&gt;]&lt;/span&gt;
        &lt;span class='n'&gt;url&lt;/span&gt; &lt;span class='o'&gt;=&lt;/span&gt; &lt;span class='n'&gt;urljoin&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;BASE_URL&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;link&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
        
        &lt;span class='c'&gt;# iteratively populate this list &lt;/span&gt;
        &lt;span class='n'&gt;urls&lt;/span&gt;&lt;span class='o'&gt;.&lt;/span&gt;&lt;span class='n'&gt;append&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;url&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;


    &lt;span class='c'&gt;# download and parse these missed connections using&lt;/span&gt;
    &lt;span class='c'&gt;# multiple threads&lt;/span&gt;
    &lt;span class='n'&gt;threaded&lt;/span&gt;&lt;span class='p'&gt;(&lt;/span&gt;&lt;span class='n'&gt;urls&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;scrape_missed_connection&lt;/span&gt;&lt;span class='p'&gt;,&lt;/span&gt; &lt;span class='n'&gt;num_threads&lt;/span&gt;&lt;span class='o'&gt;=&lt;/span&gt;&lt;span class='mi'&gt;10&lt;/span&gt;&lt;span class='p'&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;br /&gt;
&lt;p&gt;Now when we execute &lt;a href='https://github.com/abelsonlive/scrape-the-gibson/blob/master/03-multithreading.py'&gt;this script&lt;/a&gt;, it should run much, much faster than our previous scripts. Be warned, however, many sites do not appreciate you requesting multiple pages at once and may ban you from the site for throttling their servers. Make sure to excercise caution and be respectful when utilizing multiple threads to scrape a site.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;With these three simple skills, you should be able to start scraping the web like a true hacker. Enjoy!&lt;/p&gt;</description>
				<pubDate>Tue, 17 Dec 2013 00:00:00 -0500</pubDate>
				<link>http://brianabelson.com/open-news/2013/12/17/scrape-the-gibson.html</link>
				<guid isPermaLink="true">http://brianabelson.com/open-news/2013/12/17/scrape-the-gibson.html</guid>
			</item>
		
			<item>
				<title>The Relationship Between Promotion and Performance:<br/> Pageviews Above Replacement</title>
				<description>&lt;p&gt;&lt;em&gt;This is the second in a series of two posts about pageviews. This post details some research I&amp;#8217;ve conducted on the promotional correlates of the metric, while &lt;a href='http://brianabelson.com/open-news/2013/10/09/Whither-the-pageview_apocalypse.html'&gt;the previous post&lt;/a&gt; discussed the sometimes apocalyptic tone of the discourse surrounding the &amp;#8216;death&amp;#8217; of pageviews.&lt;/em&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h2 id='the_meaning_of_metrics'&gt;The Meaning of Metrics&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href='http://en.wikipedia.org/wiki/James_Watt'&gt;James Watt&lt;/a&gt; had a problem. The man erroneously known as the creator of the steam engine (he actually just added a small condenser to the existing steam engine which made it more efficient) needed a way to sell his new machine. While there were plenty of ways to measure how one steam engine compared with another, there wasn&amp;#8217;t yet a good way to compare the power of a steam engine with that of less technologically-sophisticated alternatives. &lt;br /&gt; &lt;br /&gt; So Watt came up with &lt;a href='http://en.wikipedia.org/wiki/Horsepower'&gt;horsepower&lt;/a&gt;, which was based on this simple estimation of an average horse’s strength: &lt;br /&gt; &lt;br /&gt; &lt;code&gt;
1 Horsepower = 745.699872 watts
&lt;/code&gt; &lt;br /&gt; &lt;br /&gt; With this new conversion factor, Watt was able to make the utility of his machine more marketable. Watt&amp;#8217;s engine eventually replaced horses and water wheels as the primary power source for British Industry and was one of the most crucial factors in the Industrial Revolution of the 19th century. &lt;br /&gt; &lt;br /&gt; The great irony in all of this though was that Watt’s main innovation was increasing the &lt;em&gt;efficiency&lt;/em&gt; of the steam engine, not simply its raw power. Ultimately, he made a trade-off between the degree to which horsepower reflected reality and the degree to which it could be interpreted by a lay-person. In the end, he assumed that people would take the price of coal into account, and therefore make their decisions according to two metrics: resources expended and power generated. &lt;br /&gt; &lt;br /&gt; Almost 250 years later, horsepower is still being used to sell engines. The problem, however, is that over time  —  as the cost of extracting and shipping resources around the world plummeted  —  the calculation of horsepower remained the same. One wonders how different the world might look if Watt had added a simple denominator that accounted for the resources required to generate a given amount of force; what if American auto-culture had been focused on selling efficiency and not horsepower? &lt;br /&gt; &lt;br /&gt; Here, we begin to see what metrics are for and the effects they have over time. A metric is about communicating a complex concept in interpretable and actionable terms. But when it&amp;#8217;s widely adopted  —  when an industry seeks to optimize its activities for a given metric  —  it ceases to be a mere reflection of reality. Instead, the measure comes to actively shape the industry, oftentimes leading to unforeseen manipulations and externalities. So just as the American auto-industry’s choice to optimize for power came at the expense of increased C0² emissions, incentivizing professional baseball players to hit more home runs led to the widespread use of steroids, and the success of the &lt;em&gt;Economist&lt;/em&gt;&amp;#8217;s &lt;a href='http://www.economist.com/content/big-mac-index'&gt;Big Mac Index&lt;/a&gt; inspired Argentina &lt;a href='http://www.slate.com/blogs/moneybox/2012/05/01/why_big_macs_are_cheap_in_argentina.html'&gt;to artificially depress the price of the burger&lt;/a&gt;. &lt;br /&gt; &lt;br /&gt; In News, the dominant metric is currently pageviews, which in many ways is the digital equivalent to its analog predecessor: circulation size. While Watt used the power of a horse as the metaphor for the power of his steam engine, media organizations use pageviews as a proxy for their overall reach. They’ve done this in part because pageviews are &lt;a href='http://towcenter.org/blog/confusion-online-faulty-metrics-and-the-future-of-digital-journalism/'&gt;relatively&lt;/a&gt; easy to measure and compare across articles and news outlets. However, the &lt;a href='http://aronpilhofer.com/post/27993980039/the-right-metric-for-news'&gt;&amp;#8220;landscape has changed&amp;#8221;&lt;/a&gt; and earning money in a news organization is no longer a mere function of audience size. That being said, it hasn’t stopped media outlets from optimizing their activities to maximize this metric. &lt;br /&gt; &lt;br /&gt; At their worse, companies use &lt;a href='http://www.theatlantic.com/technology/archive/2012/05/the-pernicious-myth-that-slideshows-drive-traffic/256831/'&gt;slideshows&lt;/a&gt;, &lt;a href='http://en.wikipedia.org/wiki/Link_bait'&gt;link bait&lt;/a&gt;, and &lt;a href='http://www.chicagotribune.com/news/local/chi-mug-photogallery,0,5488047.photogallery'&gt;mugshot galleries&lt;/a&gt; to &lt;a href='http://www.youtube.com/watch?v=_ogxZxu6cjM'&gt;&amp;#8220;juke the stats&amp;#8221;&lt;/a&gt;. However, innocuous activities like placing an article on the homepage, sending out an email blast, or sharing a link on social media have the same effect. That this is the case is neither good nor bad  —  it simply needs to be acknowledged before one can meaningfully make comparisons across online content. But while the promotional arms of media outlets are focused on directing interest to particular stories, their metrics do not capture the impact of these energies. Just as Watt&amp;#8217;s horsepower only accounted for the power of his engine (and not the energy required to generate it), so do pageviews fail to capture the effects of the resources expended in creating them. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h2 id='pageviews_above_replacement'&gt;Pageviews Above Replacement&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;What would pageviews look like if we controlled for promotion? This was the question I set out to explore earlier this year as a part of my &lt;a href='http://opennews.org/' target='_blank'&gt;OpenNews&lt;/a&gt; fellowship. Early on at the &lt;em&gt;Times&lt;/em&gt;, I spoke with numerous journalists and editors who expressed a desire for a better way to make comparisons across varying pieces of content. For them, the difference between 100 and 100,000 pageviews was obvious, but what if one article &lt;a href='http://publiceditor.blogs.nytimes.com/2013/08/20/who-gets-to-snow-fall-or-jockey-at-the-times-and-why/?_r=0' target='_blank'&gt; &quot;[got] to 'Snow-Fall'&quot;&lt;/a&gt; and the other didn&amp;#8217;t? &lt;br /&gt; &lt;br /&gt; An early inspiration for me in this process was the concept of &lt;a href='http://en.wikipedia.org/wiki/Wins_Above_Replacement'&gt;Wins Above Replacement&lt;/a&gt;, or WAR  —  an advanced baseball statistic developed by &lt;a href='http://en.wikipedia.org/wiki/Sabermetrics'&gt;sabermetricians&lt;/a&gt;. The idea is fairly simple: managers are interested in putting together a winning team. However, to do so, they must select the right combination of players that possess a variety of skill-sets. While it may be easy to identify high-impact players, the majority of a team&amp;#8217;s roster is made up of backups, relief pitchers, and &amp;#8220;role-players&amp;#8221; for whom it is more difficult to judge relative talent. &lt;br /&gt; &lt;br /&gt; WAR addresses this conundrum by calculating, for every player, &amp;#8220;the number of additional wins that player would contribute to a team compared to a replacement level player at that position.&amp;#8221; So, if a manager was in need of a shortstop and didn&amp;#8217;t have much to spend, he could simply open a spreadsheet of available players, filter by shortstop, and sort by WAR. The players at the top of this list should presumably contribute the greatest number of wins to the team over the course of a season. &lt;br /&gt; &lt;br /&gt; In many ways, media companies are in need of just a metric: one that effortlessly communicates value and drives decision-making. However, at the present moment, online metrics are too focused on decontextualized outcomes. But by incorporating the influence of promotion on an article&amp;#8217;s performance, we can create a set of baselines that would enable more meaningful comparisons across a wide range of content. We might call such a metric &amp;#8216;Pageviews above replacement&amp;#8217; or PAR for short, as it would allow us to determine how well a certain article performs in comparison to a similar article that received the same level of promotion. &lt;br /&gt; &lt;br /&gt; In an attempt to build a prototype of PAR, I collected as much data as I could on the promotional activities of the &lt;em&gt;New York Times&lt;/em&gt;. Every 10 minutes or so, I pulled in the posts from 20 &lt;em&gt;Times&lt;/em&gt; Facebook accounts, 200 Twitter accounts, and the contents of the homepage and ~ 25 sections fronts. At the same time, I also collected metadata on articles and information on their performance. By cross-referencing these two sources by URL and time, I was able to construct a detailed database of 21,000 articles published on &lt;a href='http://nytimes.com'&gt;nytimes.com&lt;/a&gt; between July and August. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h2 id='exploring_the_data'&gt;Exploring the Data&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;Throughout my stint at the &lt;em&gt;Times&lt;/em&gt; I have often witnessed analysts, social media editors, journalists, and business executives sprung into action when a particular piece of content is not meeting its expectations. In most cases, the solution is to intensify promotional efforts. Whether it be through a concentrated social media campaign or simply leaving the article on the homepage longer than normal, the inevitable result is that traffic to the article increases. Following this behavioral pattern, I expected to see a clear relationship in the data between promotional energies and pageviews.&lt;br /&gt;&lt;br /&gt; In the chart below, the data is visualized over time. The y-axis connotes the total number of pageviews the article received over seven days while the x-axis represents when the article was published. Pageviews are transformed along a &lt;a href='http://www.explainxkcd.com/wiki/index.php?title=1162:_Log_Scale'&gt;logarithmic scale&lt;/a&gt; in which the differences between points correspond to orders of magnitude, rather than the raw number (in other words, the actual difference between points lower in the scale is much smaller than those higher up). In this chart and the others that follow, I remove axis annotations for pageviews so as to protect the privacy of the &lt;em&gt;New York Times&lt;/em&gt;. Finally, each dot is colored by the time the article spent on the homepage and sized by the number of times it was tweeted by a &lt;em&gt;New York Times&lt;/em&gt; Twitter account. For context, I add a line through the middle that represents the average number of pageviews for articles published on each day.&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;&lt;center&gt;
  &lt;a href='/img/posts/pageviews-above-replacement/viz/life-of-the-data.png' rel='shadowbox'&gt;
    &lt;img src='/img/posts/pageviews-above-replacement/viz/life-of-the-data.png' /&gt;
    &lt;center&gt; &lt;small&gt; &lt;i&gt; Click to Enlarge&lt;/i&gt; &lt;/small&gt; &lt;/center&gt;
  &lt;/a&gt;
&lt;/center&gt;&lt;br /&gt;&lt;br /&gt;
&lt;p&gt;At first glance, this chart appears to resemble a series of balloons floating upwards. The metaphor is apt  —  articles which spend longer on the homepage (reddish bubbles) and which are tweeted more by &lt;em&gt;Times&lt;/em&gt; accounts (larger bubbles) always rise higher. Below the average line, there are no &lt;a href='http://www.youtube.com/watch?v=e2Y1tRBOXfA'&gt;big red balloons&lt;/a&gt;. &lt;br /&gt; &lt;br /&gt; Following this insight, we might wonder how strong the relationship between time on homepage, number of tweets, and pageviews is. The chart below visualizes these relationships by placing articles in a scatterplot, where the x-axis is the time an article spent on the homepage (log-scaled), the y-axis is the number of pageviews (once again, log-scaled), and the size of each point corresponds to the number of times the article was tweeted by &lt;em&gt;Times&lt;/em&gt; accounts. In addition, the dots are now colored according to the four combinations of two variables  —  whether or not an article was from the AP or Reuters (&amp;#8220;the wire&amp;#8221; for short) and whether or not an article was tweeted by &lt;a href='http://www.twitter.com/nytimes'&gt;@NYTimes&lt;/a&gt;. &lt;br /&gt; &lt;br /&gt; &lt;center&gt;
&lt;table&gt;
    &lt;tr style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666; background: rgba(255, 99, 71, .7);'&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;Original content, no @NYTimes tweets&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;4553 Articles&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;21.7%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666; background: rgba(70, 130, 180, .7);'&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;Wire content, no @NYTimes tweets&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;15180 Articles&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;72.2%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666; background: rgba(255, 204, 0, .7);'&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;Original content, tweeted by @NYTimes&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;1184 Articles&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;5.6%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666; background: rgba(255, 0, 204, .7);'&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;Wire content, tweeted by @NYTimes&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;89 Articles&lt;/td&gt;
        &lt;td style='border-width: 1px; padding: 8px; border-style: solid; border-color: #666666;'&gt;0.4%&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt; &lt;br /&gt; &lt;br /&gt; Through my explorations of the data, I found that these two variables were significantly associated with the number of pageviews an article received (discussed more below). Intuitively it makes sense  —  stories from the wire should not receive the same promotional energies as those that come from journalists working at the &lt;em&gt;Times&lt;/em&gt;. Likewise, articles which are exposed to @NYTimes&amp;#8217; 10 million followers will invariably perform better than those which do not receive this boost. &lt;br /&gt; &lt;br /&gt; &lt;br /&gt; &lt;center&gt;
  &lt;a href='/img/posts/pageviews-above-replacement/viz/time-on-hp-vs-pageviws-social-wire.png' rel='shadowbox'&gt;
    &lt;img src='/img/posts/pageviews-above-replacement/viz/time-on-hp-vs-pageviws-social-wire.png' /&gt;
    &lt;center&gt; &lt;small&gt; &lt;i&gt; Click to Enlarge&lt;/i&gt; &lt;/small&gt; &lt;/center&gt;
  &lt;/a&gt;
&lt;/center&gt; &lt;br /&gt; &lt;br /&gt; This chart shows the stark contrast in the lives of articles that pass through the &lt;em&gt;New York Times&lt;/em&gt;. On the left side of the graph, we see a stack of 13,000 articles (73% of the total) which were never promoted on the homepage. These articles exist in somewhat of an online &lt;a href='http://en.wikipedia.org/wiki/State_of_nature'&gt;&amp;#8216;State of Nature&amp;#8217;&lt;/a&gt; and for most, their lives are &lt;a href='http://en.wikipedia.org/wiki/Leviathan_(book)'&gt;nasty, brutish, and short&lt;/a&gt;. Of these, about two-thirds are wire content. The other third are stories from &lt;em&gt;Times&lt;/em&gt; journalists, two percent of which were also tweeted by @NYTimes. Just to the right of this stack is content which was on the homepage for 10 - 100 minutes. Of these, a shockingly high 98% are wire articles. In this space, the articles that performed especially well were the fortunate one percent linked to by @NYTimes. Finally, on the right half of the chart are the six percent of articles which spent more than 100 minutes on the homepage. Over 90% of these articles are original content and almost 80% were promoted by @NYTimes. &lt;br /&gt; &lt;br /&gt; What emerges from this visualization is a clear picture of four distinct classes of content on the New York Times&amp;#8217; site: (A) Wire articles which never reached the homepage, (B) Original articles which never reached the homepage, (C) Wire content which is featured on the homepage for a short period of time, and (D) Original content which receives promotion on both the homepage and across social media. While groups A and B encompass a wide variety of outcomes, groups C and D generally display a positive linear relationship between time on homepage and pageviews. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h2 id='predicting_pageviews'&gt;Predicting Pageviews&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;Given these clear relationships, I wondered how well I could predict pageviews. The idea here is that, by determining the factors that drive traffic to an article, we can create baselines that help us determine whether or not an article has underperformed or exceeded its expectations. &lt;br /&gt; &lt;br /&gt; Surprisingly, I found that the three factors visualized above  —  whether or not an article was from the wire, whether it was tweeted by @NYTimes, and how long it spent on the homepage  —  accounted for over 70% of the variance in pageviews within my dataset. By including additional variables in my model  —  the type of content (video, interactive, blogpost, or article), the section the article came from, word count, promotion on Facebook and section fronts, and the highest point the article reached on the homepage  —  I was able to explain almost 90% of the variance in pageviews. This means that, given some basic information about an article and the degree to which it will be promoted, my model can, to a fairly high level of precision, predict how many pageviews that article will receive seven days after publication. &lt;br /&gt; &lt;br /&gt; Of the variables included in the model, ten proved to have the highest predictive value:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Time on all section fronts (+)&lt;/li&gt;

&lt;li&gt;Number of unique section fronts reached (+)&lt;/li&gt;

&lt;li&gt;Was the article in the paper? (+)&lt;/li&gt;

&lt;li&gt;Was the article tweeted by @NYTimes? (+)&lt;/li&gt;

&lt;li&gt;Time on homepage (+)&lt;/li&gt;

&lt;li&gt;Number of NYT-tweets (+)&lt;/li&gt;

&lt;li&gt;Max rank on homepage (+)&lt;/li&gt;

&lt;li&gt;Word count (+)&lt;/li&gt;

&lt;li&gt;Is the article from Reuters? (-)&lt;/li&gt;

&lt;li&gt;Is the article from the AP? (-)&lt;/li&gt;
&lt;/ul&gt;
&lt;i&gt;+/- symbols signify the direction of correlation&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;
&lt;p&gt;While it may be tempting to latch on to any one of these variables, the general idea is that, holding all else constant, articles which receive more promotion  —  on the homepage, across section fronts, and on social media  —  will invariably receive more pageviews. While there are some serious problems in such an analysis  —  it is likely that content which performs well tends to attract the attention of homepage and social media editors  —  the power of the relationship suggests that, in general, the &lt;em&gt;Times&lt;/em&gt; can selectively pick and choose the content that garners the most attention by simply manipulating their homepage and principal Twitter account. This is certainly not an earth-shattering insight, but the degree to which it holds true suggests that these factors cannot be ignored. &lt;br /&gt; &lt;br /&gt; Below, I visualize a scatterplot of the actual number of pageviews versus the number my model predicted. Once again, dots are colored by the four categories outlined above, with lines pointing to the average number of pageviews for each category. &lt;br /&gt; &lt;br /&gt; &lt;center&gt;
  &lt;a href='/img/posts/pageviews-above-replacement/viz/pred-vs-actual.png' rel='shadowbox'&gt;
    &lt;img src='/img/posts/pageviews-above-replacement/viz/pred-vs-actual.png' /&gt;
    &lt;center&gt; &lt;small&gt; &lt;i&gt; Click to Enlarge&lt;/i&gt; &lt;/small&gt; &lt;/center&gt;
  &lt;/a&gt;
&lt;/center&gt; &lt;br /&gt; &lt;br /&gt; While this chart mainly communicates the predictive power of the model, it also reveals some other interesting insights. For instance, there is a much higher level of variance  —  or predictive error in the model  —  at lower levels of pageviews. This is the manifestation of the &amp;#8216;State of Nature&amp;#8217; described above. Since promotional energies are such strong a predictor of performance, articles that receive very little promotion are harder to predict. Further investigation confirmed that the majority of the error in my model was present in articles which never reached the homepage. &lt;br /&gt; &lt;br /&gt; More importantly, the relationship between actual and predicted pageviews represents a fundamental building block of PAR. In the graph, the straight gray line signifies the threshold of a perfect prediction. Articles that fall above this line can be thought to have exceeded their expected number of pageviews while those below the line have underperformed. Computing the error of the model, or the difference between actual and predicted pageviews, allows us to calculate the degree to which any given article has performed in relationship to its &amp;#8220;replacement&amp;#8221;  —  or a hypothetically similar article which received the same level of promotion. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h2 id='calculating_par'&gt;Calculating PAR&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;While I am still in the nascent stages of this research, I explored what PAR might look like if we were to use it to evaluate the performance of various sections on the &lt;em&gt;New York Times&lt;/em&gt;. Below I visualize the average PAR  —  or the degree to which a given article&amp;#8217;s actual number of pageviews deviated from the number my model predicted  —   for the top sections in terms of the number of articles produced. In the chart, the x-axis represents standard deviations  —  or the distance a data point is from its mean  —  so that we may compare multiple variables on the same scale. The x-position of reddish dots signifies a section&amp;#8217;s average PAR. These dots are also sized by the average number of times NYT Twitter accounts shared a link to an article in a given section. Concurrently, the x-position of blue dots signifies the average pageviews for articles from each section. These dots are sized by the total number of articles published in that section. Finally, the lines connecting these two sets of dots are colored by the average time articles from these sections were promoted on the homepage. &lt;br /&gt; &lt;br /&gt; &lt;center&gt;
  &lt;a href='/img/posts/pageviews-above-replacement/viz/par-by-section.png' rel='shadowbox'&gt;
    &lt;img src='/img/posts/pageviews-above-replacement/viz/par-by-section.png' /&gt;
    &lt;center&gt; &lt;small&gt;&lt;i&gt;Click to Enlarge&lt;/i&gt; &lt;/small&gt; &lt;/center&gt;
  &lt;/a&gt;
&lt;/center&gt; &lt;br /&gt; &lt;br /&gt; As the annotations on the chart suggest, PAR significantly levels the playing field. While Business, US, Technology, World, and Sports all rank much lower with regards to raw pageviews, PAR accounts for their relatively low level of promotion (visualized by the blue lines and small red dots). In turn, these sections rank in the middle of pack with regards to PAR. On the other hand, Opinion, Magazine, and Real Estate pieces, which rank high in terms of pageviews, are not so far ahead when calculating PAR. It is important to note, of course, that content which garners an extreme amount of traffic will still rank high in terms of PAR, as these signify outliers from the norm, and the model will never be able to fully account for these deviations. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h2 id='next_steps'&gt;Next Steps&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;While the research I&amp;#8217;ve outlined above represents a very small step in creating a better set of metrics for online media, it powerfully suggests that the placement of promotional data alongside pageviews gives us a better understanding of what the metric actually means. To make these insights actionable, we might imagine an application which tracks, in real time, how articles are being promoted across an organization&amp;#8217;s social media accounts and website. This application would then make a prediction of how many pageviews (or really any outcome, for that matter) an article should have received at an arbitrary point in time given the level of promotion it garnered up to that point. By concurrently tracking the performance of an article over time, it could also make predictions about the future, which would aid in deciding whether additional promotion of an article will have a meaningful effect. Researchers from MIT, Carnegie Mellon, and the Qatar Computing Research Institute have recently created &lt;a href='http://fast.qcri.org/'&gt;a similar application for Al Jazeera&lt;/a&gt;, and have outlined their findings in &lt;a href='http://arxiv.org/pdf/1304.3010v3.pdf'&gt;an academic article&lt;/a&gt;. I have also begun work &lt;a href='https://github.com/abelsonlive/par_data'&gt;on open-source application&lt;/a&gt; (documentation is coming!) which tracks an arbitrary set of Twitter accounts, Facebook pages, websites, and RSS feeds, and detects and archives when links that match a certain pattern appear. This application could be used in tandem with Google Analytics (or any other analytics software) to create a dataset similar to the one I&amp;#8217;ve outlined above. &lt;br /&gt; &lt;br /&gt; An important task in furthering this research will be to apply it to contexts outside of the &lt;em&gt;New York Times&lt;/em&gt;. The variance in promotional strategies across media organizations is vast, and it is likely that the factors which drive pageviews for the &lt;em&gt;Times&lt;/em&gt; are not the same for nonprofit news sites like &lt;a href='http://propublica.org'&gt;ProPublica&lt;/a&gt; or social media-oriented outlets like &lt;a href='http://qz.com'&gt;Quartz&lt;/a&gt;. The &lt;em&gt;Times&lt;/em&gt; is most certainly an outlier with regards to the level which its homepage drives traffic, and in the future  —  as social media becomes an increasingly important mechanism for content discovery  —  the significance of homepages will invariably diminish. Another issue is the fact that, more and more, news organizations are serving different content to different users based on their perceived preferences. In this world, it will be very difficult to determine the degree to which certain pieces of content are &amp;#8220;promoted&amp;#8221; more than others. &lt;br /&gt; &lt;br /&gt; In sum, the PAR approach is a band-aid  —  it does not fully dissolve the importance of pageviews nor does it anticipate the changes in the media landscape to come. It cannot tell you anything about the broader impact a piece of reporting has on society, nor does it &amp;#8216;Save Journalism&amp;#8217; in one fell swoop. At best, PAR helps communicate the importance of measuring inputs, or the energy expended by a news organization to achieve a certain goal. While measuring promotional input is an important first step, we might also imagine a set of metrics which account for the time it took to put a story together or the money spent on pulling in content from the wire. As my esteemed colleague &lt;a href='https://twitter.com/JamesGRobinson'&gt;James Robinson&lt;/a&gt; likes to say, news analytics is about &amp;#8220;measuring the relationship between impact and effort.&amp;#8221; For too long we have been focused on measuring the former while ignoring the latter. It&amp;#8217;s time to change that. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;</description>
				<pubDate>Thu, 14 Nov 2013 00:00:00 -0500</pubDate>
				<link>http://brianabelson.com/open-news/2013/11/14/Pageviews-above-replacement.html</link>
				<guid isPermaLink="true">http://brianabelson.com/open-news/2013/11/14/Pageviews-above-replacement.html</guid>
			</item>
		
			<item>
				<title>Whither the Pageview Apocalypse?</title>
				<description>&lt;p&gt;&lt;em&gt;This is the first in the series of two posts about pageviews. This post will deal with some of theoretical baggage tied up in the metric, while the second will detail some research I&amp;#8217;ve conducted on the correlates of pageviews.&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;#8220;Wild, dark times are rumbling toward us, and the prophet who wishes to write a new apocalypse will have to invent entirely new beasts, and beasts so terrible that the ancient animal symbols of St. John will seem like cooing doves and cupids in comparison.&amp;#8221; – Heinrich Heine, &lt;em&gt;Lutetia; or, &amp;#8216;Paris&amp;#8217;&lt;/em&gt;, Augsberg Gazette, 1842&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;p&gt;The pageview is dead. Jeff Jarvis &lt;a href='http://www.theguardian.com/media/2007/jan/15/mondaymediasection5' target='_blank'&gt;presided over its wake in 2007&lt;/a&gt;, soberly preparing us for a brave new world of Flash, AJAX, and embeddable widgets in which a page was no longer &lt;em&gt;just a page&lt;/em&gt;. Chartbeat announced its death &lt;a href='http://blog.chartbeat.com/2012/01/10/metrics-that-matter-and-death-of-the-page-view/' target='_blank'&gt;as early as 2012&lt;/a&gt; and most recently in a &lt;a href='http://ona13.journalists.org/2013/10/03/metrics-can-improve-newsrooms-but-only-if-the-culture-is-ready/' target='_blank'&gt;sponsored post for the Online News Association's upcoming conference&lt;/a&gt;. My current position as a &lt;a href='http://www.mozillaopennews.org/fellowships/2013meet.html' target='_blank'&gt;2013 Knight-Mozilla OpenNews Fellow&lt;/a&gt; was granted a messianic status when some equated the fellowship to &lt;a href='https://twitter.com/rsingel/status/266602336963686400' target='_blank'&gt;a violent crusade against the metric&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;Yet, when I open Google Analytics, I am presented with a time series chart of pageviews. Most newsrooms I visit include a &amp;#8216;big board&amp;#8217; with a list of the top ten articles by pageviews.** And when I sit in analytics meetings, I regularly hear the metric tossed around as a means of benchmarking one article against another. If, as I&amp;#8217;ve been led to believe, this is a post-pageview world, then we must be living in a zombie apocalypse as I&amp;#8217;m relentlessly haunted by the metric&amp;#8217;s lifeless corpse.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;What then of the pageview apocalypse and the prophets who giddily proclaim it? To what ends are these revelations leading us? What strategic aims and benefits are these claims predicated upon?&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;In Jacques Derrida&amp;#8217;s 1982 essay, &lt;a href='http://bit.ly/GN1uaY' target='_blank'&gt;&lt;em&gt;Of an Apocalyptic Tone Newly Adopted in Philosophy&lt;/em&gt;&lt;/a&gt;, he writes of a tendency prevalent in academia in which scholars paradoxically announce the &amp;#8216;death&amp;#8217; or &amp;#8216;end&amp;#8217; of their fields. This same tendency can be located in art and culture when critics bemoan the death of &lt;a href='http://www.xxlmag.com/news/bloggers/2006/05/the-death-of-hip-hop/' target='_blank'&gt;Hip-Hop&lt;/a&gt; or &lt;a href='http://www.academia.edu/156134/The_Death_and_Life_of_Punk_The_Last_Subculture' target='_blank'&gt;Punk&lt;/a&gt;. The last decade of the News Industry has often resembled the final minutes of &lt;em&gt;Reservoir Dogs&lt;/em&gt;, with publications announcing the demise of their counterparts only to be shot down themselves in the following frame. There is even &lt;a href='http://newspaperdeathwatch.com/' target='_blank'&gt;an online newspaper dedicated to the death of newspapers&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;For Derrida, though, such apocalyptic declarations are intriguing not for the end they depict, but for the transformative visions embedded within their rhetoric. Grounding his discussion in etymology, &amp;#8216;apocalypse&amp;#8217; is derived from the Greek &lt;a href='http://www.biblestudytools.com/lexicons/greek/nas/apokalupsis.html' target='_blank'&gt;&lt;em&gt;apokalupsis&lt;/em&gt;&lt;/a&gt; which translates to &amp;#8220;reveal&amp;#8221; or to &amp;#8220;uncover.&amp;#8221; In the Hebrew Bible, the equivalent word &lt;a href='http://www.biblestudytools.com/lexicons/hebrew/nas/gala.html' target='_blank'&gt;&lt;em&gt;gala&lt;/em&gt;&lt;/a&gt; is used over a hundred times saying in effect &amp;#8220;disclosure, uncovering, unveiling, the veil lifted from about the thing,&amp;#8221; most often in reference to the sex and/or genitalia of a man or woman, but also in reference to their sensory organs (eyes, ears, mouth). &amp;#8216;Apocalypse’, then, literally means the act of uncovering: the removing of clothes, the shifting of hair, or the unveiling of eyes to reveal a secret or unknowable existence just beyond the surface. In this manner, an apocalypse is &amp;#8220;essentially a contemplation,&amp;#8221; or a meditation upon a veiled state, which is structured by a desire of a particular disclosure or revelation to its thought process.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;So what is being revealed when the death of the pageview is proclaimed? Our first clue comes from the coroners. More often than not, they are the stewards of Web Analytics, an industry that was largely built upon measuring pageviews. From &lt;a href='http://ona13.journalists.org/2013/10/03/metrics-can-improve-newsrooms-but-only-if-the-culture-is-ready/' target='_blank'&gt;Chartbeat&lt;/a&gt;, to &lt;a href='http://blog.kissmetrics.com/throw-away-vanity-metrics/' target='_blank'&gt;KISSmetrics&lt;/a&gt;, to &lt;a href='http://blogs.webtrends.com/2010/07/web-analytics-is-dead-long-live-web-analytics/' target='_blank'&gt;WebTrends&lt;/a&gt;, and &lt;a href='http://www.computerworld.com/s/article/9026640/New_Nielsen_Web_metric_likely_to_hurt_Google_help_YouTube?intsrc=hm_list' target='_blank'&gt;Nielsen&lt;/a&gt;, it seems like every analytics company has shared in the apocalyptic glee. Mixpanel, a particularly brazen analytics startup, even purchased billboard space along Highway 101 to announce the death of the pageview: &lt;br /&gt; &lt;br /&gt; &lt;center&gt;&lt;img src='https://dl.dropboxusercontent.com/u/6535582/mixpanel-pageviews-are-dead.png' width='400px' /&gt;&lt;/center&gt; &lt;br /&gt; &lt;p&gt; Remind you of anything? &lt;/p&gt; &lt;br /&gt; &lt;center&gt;&lt;img src='http://www.writeonnewjersey.com/wp-content/uploads/2011/04/Judgment-Day-Billboard1.jpg' width='400px' /&gt;&lt;/center&gt; &lt;br /&gt; &lt;br /&gt; Why then are so many analytics companies taking up arms against themselves? What is the meaning of this &lt;a href='http://stdout.be/2013/08/26/cargo-cult-analytics/' target='_blank'&gt;cargo cult&lt;/a&gt; of counter-analytics? Here, we can use the common structure of the above billboards as our guide:&lt;/p&gt;
&lt;br /&gt;
&lt;ol&gt;
&lt;li&gt;Loudly announce the end.&lt;/li&gt;

&lt;li&gt;Suggest a counter-action.&lt;/li&gt;
&lt;/ol&gt;
&lt;br /&gt;
&lt;p&gt;In almost every case, when we are told the pageview is dead, we are given a list of metrics that will take its place. This is the revelation. Instead of pageviews, we&amp;#8217;re advised, we should be quantifying engagement, trying out A/B tests, conducting funnel analyses, or deploying click/event tracking on our sites (conveniently enough, these tools have often just been added to the next iteration of their platforms). And it&amp;#8217;s not that these metrics are useless - they can be of great value when designed and deployed correctly - it&amp;#8217;s that, in lieu of a critical assessment of how and why pageview-centric platforms failed us, we are instead told that &lt;a href='http://readwrite.com/2010/03/17/the-death-of-the-pageview' target='_blank'&gt;our egotism led us to pay attention to the wrong things in the first place&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;Yet, having experimented with many &amp;#8220;actionable&amp;#8221;, rather than &lt;a href='http://www.fourhourworkweek.com/blog/2009/05/19/vanity-metrics-vs-actionable-metrics/' target='_blank'&gt;&quot;vanity metrics,&quot;&lt;/a&gt; I can tell you that their results are often just as murky and misleading. Engagement is a moving target; A/B tests, when poorly designed, often produce inconclusive results; event tracking, while incredibly powerful, does not readily enable comparisons across varied contexts. And, even when these tools are utilized to their full potential, it can be very difficult to translate their insights into action. The fact of the matter is that there are no silver bullets, no secrets to be revealed just beyond the pageview. All there is is hard work, open dialogue, and relentless experimentation to find what works in your particular context. After all, we&amp;#8217;re talking about measuring the complex behaviors of millions of people.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;Still, many will try and seduce you into believing otherwise. This act of seduction, Derrida explains, is the principal strategy of apocalypticism:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;#8220;the subject of &lt;span&gt;apocalyptic&lt;/span&gt; discourse can have an interest in forgoing its own interest, can forgo everything in order to place yet its death on your shoulders and make you inherit in advance its corpse, that is, its soul, the subject hoping thus to arrive at its end through the end&amp;#8221; (52).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this powerful, if enigmatic passage, we begin to understand the true motivations of apocalyptic prophets. Doomsayers do not merely seek acknowledgement of an end-to-come or one that has already passed, they are more concerned with seducing you into accepting the terms on which their continued existence, their vested interests, and their vision of &amp;#8216;the end&amp;#8217; &lt;em&gt;are all equally possible&lt;/em&gt;. It&amp;#8217;s not that analytics platforms are flawed, they say, it&amp;#8217;s simply that you&amp;#8217;re not paying attention to the right parts; It&amp;#8217;s not that insights are difficult, they promise, it&amp;#8217;s that you&amp;#8217;ve been going about finding them in the wrong way.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;So when we are told that the &amp;#8216;pageview is dead&amp;#8217;, what we are actually being told is that &amp;#8216;analytics platforms are dying&amp;#8217;; that the current paradigm is fundamentally flawed and that the companies responsible are scrambling to convince us otherwise. And, rather than accepting their share of the blame, they cite our inherent egotism - our blindly narcissistic desire for validation - in a plot to absolve themselves of guilt and justify their importance. In this vision of the apocalypse, &lt;a href='http://en.wikipedia.org/wiki/Babylon_(New_Testament)' target='_blank'&gt;Babylon&lt;/a&gt; is inhabited by the users of metrics, not their marketers or makers.&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;#8220;This is the way the world ends. Not with a bang but a whimper.&amp;#8221; - T.S. Elliot, &lt;em&gt; The Hollow Men &lt;/em&gt;, 1925&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While the &lt;a href='http://mathbabe.org/2013/09/20/the-bursting-of-the-big-data-bubble/' target='_blank'&gt;big data bubble&lt;/a&gt; has inflated quickly, it will not simply &amp;#8216;pop&amp;#8217;. So, instead of worrying about whether we&amp;#8217;re measuring the wrong things, or using the wrong tools or software, or falling behind the competition, let&amp;#8217;s take a deep breath, ignore the doomsayers, and do the best we can with what we have right now. And, if after a while, that&amp;#8217;s still not working, then perhaps we should reassess precisely why, in what manner, and by whom we were convinced that analytics would solve our problems in the first place.&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;p&gt;&lt;em&gt;Correction: The original version of this essay contained the sentence, &amp;#8220;When I glance at the Chartbeat dashboard looming above my desk, I see a list of the top five articles by pageviews on the New York Times’ site.&amp;#8221; In fact, Chartbeat does not measure &amp;#8220;pageviews&amp;#8221;, but &amp;#8220;concurrent visitors.&amp;#8221; Read more about it &lt;a href='http://support.chartbeat.com/customer/portal/articles/1249454-where-can-i-find-page-views-?b_id=226'&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
				<pubDate>Wed, 09 Oct 2013 00:00:00 -0400</pubDate>
				<link>http://brianabelson.com/open-news/2013/10/09/Whither-the-pageview_apocalypse.html</link>
				<guid isPermaLink="true">http://brianabelson.com/open-news/2013/10/09/Whither-the-pageview_apocalypse.html</guid>
			</item>
		
			<item>
				<title>One year after 'Finding the right metric for news</title>
				<description>&lt;p&gt;&lt;em&gt;This is the first in the series of two posts about pageviews. This post will deal with some of theoretical baggage tied up in the metric, while the second will detail some research I&amp;#8217;ve conducted on the correlates of pageviews.&lt;/em&gt; A year ago today, Aron Pilhofer, head of Interactive News at the New York Times, wrote a &lt;a href='http://aronpilhofer.com/post/27993980039/the-right-metric-for-news'&gt;blog post&lt;/a&gt; that changed my life. In it he reflected on the impoverished status of newsroom analytics, soberly claiming:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;#8221;&amp;#8230;the benchmarks we use now are so ill suited. They are the simplistic, one-dimensional metrics we all know: pageviews, time on site, uniques. We use them largely because they are there and because they are easy&amp;#8221;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The lack of suitable metrics for measuring impact, he argued, was the key to journalism&amp;#8217;s survival in a digital environment and the perfect issue for a &lt;a href='http://www.mozillaopennews.org/fellowships/'&gt;Mozilla-Knight OpenNews Fellow&lt;/a&gt; to address over a yearlong fellowship.&lt;/p&gt;

&lt;p&gt;At the time I read this I was a grad student struggling through the process of translating my questions into maths and code. While I had completed &lt;a href='http://brianabelson.com/assets/sqfmosques.pdf'&gt;some cool projects&lt;/a&gt;, it had been three months since I had copy-and-pasted my way though &lt;a href='http://www.youtube.com/embed/OEkNu3HIn58'&gt;a 5000 line script because I was scared of SQL databases&lt;/a&gt; and six since I first opened that &amp;#8216;scary program called Terminal&amp;#8217; on my MacBook.&lt;/p&gt;

&lt;p&gt;So when I read Aron&amp;#8217;s eventual pitch - &amp;#8220;If you’re an analytics nerd, a news junkie and think it would be neat to spend some time using The New York Times newsroom as your laboratory, we’d like to hear from you&amp;#8221; - I was both thrilled and horrified. How could I - neither a hack nor a hacker - compete with the plethora of geniuses that would no doubt apply for such an irresistible position. Like Noah Veltman, my remarkable friend and &amp;#8216;fellow fellow&amp;#8217;, &lt;a href='http://veltman.tumblr.com/post/56132893301/code-the-newsroom-and-self-doubt'&gt;&amp;#8220;I had a serious case of imposter syndrome&amp;#8221;&lt;/a&gt;. This deep sense of self doubt (and perhaps a little procastination) led me to mull over the application to &lt;a href='http://www.niemanlab.org/2012/11/luring-developers-into-the-newsroom-a-new-class-of-knight-mozilla-fellows-tries-to-bridge-a-cultural-divide/'&gt;&lt;em&gt;literally the last second&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Since then, I&amp;#8217;ve undergone a transformation that is no less than miraculous. In my five-plus months as a fellow I&amp;#8217;ve dove deep into the technical and intellectual challenges of impact measurement, &lt;a href='http://brianabelson.com/open-news/2013/04/02/Impact-Bibliography.html'&gt;reading as much as I could find on the topic&lt;/a&gt;, &lt;a href='http://brianabelson.com/open-news/2013/03/18/A-Metric-For-News-Apps.html'&gt;experimenting with the creation of metrics for News Apps&lt;/a&gt;, &lt;a href='http://vimeo.com/65113344'&gt;speaking at conferences&lt;/a&gt;, and conversing with the brightest minds in the field. I have been continually humbled at the many people working on this problem for no other reason than they think it&amp;#8217;s the right thing to do. I&amp;#8217;ve also found support in the many innovators and brainiacs I work with at the &lt;em&gt;New York Times&lt;/em&gt; and the &lt;a href='http://www.mozillaopennews.org/fellowships/2013meet.html'&gt;seven incredible people&lt;/a&gt; I&amp;#8217;ve shared this journey with.&lt;/p&gt;

&lt;p&gt;In this time, I&amp;#8217;ve gone from a novice coder with some knowledge of stats to someone who regularly writes map-reduce jobs over terrabytes of data (trust me, if you&amp;#8217;re a data nerd, the New York Times is your perverse playground). The freedom of the fellowship has also allowed me to pursue more whimsical projects like &lt;a href='https://twitter.com/haikugrams'&gt;building haikubots&lt;/a&gt;, &lt;a href='http://www.meetup.com/nyhackr/events/111193682/'&gt;experimeting&lt;/a&gt; &lt;a href='https://github.com/csv/ddr'&gt;with&lt;/a&gt; &lt;a href='http://fms.csvsoundsystem.com/'&gt;data sonification&lt;/a&gt;, and writing oh-so-many &lt;a href='https://github.com/abelsonlive/regextweet'&gt;twitter trolls&lt;/a&gt;. I&amp;#8217;ve also had the priveledge of working with my friends in &lt;a href='http://csvsoundsystem.com'&gt;csv soundsystem&lt;/a&gt; to build &lt;a href='http://treasury.io'&gt;treasury.io&lt;/a&gt; - a daily data feed for the U.S. Treasury.&lt;/p&gt;

&lt;p&gt;And after all of this I can say that while my initial fears of technical incompetency weren&amp;#8217;t completely unfounded, I was perhaps afraid of the wrong things. To return to the question that launched this crazy adventure in the first place - &lt;a href='http://www.greglinch.com/2012/01/quantifying-impact-a-better-metric-for-measuring-journalism.html'&gt;&amp;#8220;what if we measured journalism by its impact?&amp;#8221;&lt;/a&gt; - I&amp;#8217;d be remiss to not complicate the current conceptualization of the problem. This perspective has been deeply informed by my interactions with &lt;a href='https://twitter.com/jamesgrobinson'&gt;James Robinson&lt;/a&gt;, my friend and mentor at the &lt;em&gt;Times&lt;/em&gt; who, in sharing his vast experience in news analytics, has often served as my version of &lt;a href='http://www.youtube.com/watch?v=2Zail7Gdqro'&gt;Gene Wilder in &lt;em&gt;Charlie and the Chocolate Factory&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;What I think we&amp;#8217;ve learned in our experimentation with news metrics is that, more than anything, our work is less about programming than it is about proselityzing. The challenge of changing the approach to metrics in the news room is nothing less than that of sparking social and cultural change. The question we must be asking, then, is the painfully meta one of &amp;#8220;how do we measure the impact of impact measurement?&amp;#8221; If the tools, methodologies, and metrics we develop are difficult to use, implement, or understand, then the journalists and editors we&amp;#8217;re trying to influence will fall back on their well-honed instincts. The key is not to prove whether a story or news organization has &amp;#8216;made an impact&amp;#8217; but to help journalists make data driven decisions that resonate with their broader goals. This challenge, I think, is more anthropological than statistical, more collaborative than code-based.&lt;/p&gt;

&lt;p&gt;So while I think I&amp;#8217;ve done alot to tackle the difficult set of questions I&amp;#8217;ve been tasked with, in many ways I&amp;#8217;ve failed miserably. In my final five months I hope I can do more to build and write things that help more people. But there&amp;#8217;ll always be more work. So if you know a bit of code or maths and think insights trump data, then &lt;a href='http://www.mozillaopennews.org/fellowships/'&gt;apply to become a 2014 OpenNews Fellow&lt;/a&gt; and pick up where I and my other fellows have left off.&lt;/p&gt;</description>
				<pubDate>Thu, 25 Jul 2013 00:00:00 -0400</pubDate>
				<link>http://brianabelson.com/open-news/2013/07/25/One-year-after-finding-a-metric-for-news.html</link>
				<guid isPermaLink="true">http://brianabelson.com/open-news/2013/07/25/One-year-after-finding-a-metric-for-news.html</guid>
			</item>
		
			<item>
				<title>An impact reading list</title>
				<description>&lt;br /&gt;
&lt;h2 id='edit_this_document'&gt;&lt;a href='http://bit.ly/EditImpactBibliography'&gt;EDIT THIS DOCUMENT&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id='whats_in_here'&gt;What&amp;#8217;s in here?&lt;/h3&gt;

&lt;p&gt;This bibliography contains a smattering of pieces, long and short, that are relevant to the study of media impact. From blog posts and case studies to fully-developed frameworks for analysis, reading selections from this list should quickly get you up to speed with the field.&lt;/p&gt;
&lt;br /&gt;
&lt;h3 id='where_do_i_start'&gt;Where do I start?&lt;/h3&gt;

&lt;p&gt;There are so many good pieces in here, but these are three of my favorites:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tofel, Richard J., &amp;#8220;Non-profit journalism &amp;#8211; Issues around impact: A white paper from ProPublica,&amp;#8221; February, 2013. &lt;a href='http://s3.amazonaws.com/propublica/assets/about/LFA_ProPublica-white-paper_2.1.pdf'&gt;http://s3.amazonaws.com/propublica/assets/about/LFA_ProPublica-white-paper_2.1.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Stray, Jonathan, “Metrics, metrics everywhere: How do we measure the impact of journalism?,&amp;#8221; Nieman Journalism Lab, August 17, 2012. &lt;a href='http://www.niemanlab.org/2012/08/metrics-metrics-everywhere-how-do-we-measure-the-impact-of-journalism/'&gt;http://www.niemanlab.org/2012/08/metrics-metrics-everywhere-how-do-we-measure-the-impact-of-journalism/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Linch, Greg, &amp;#8220;Quantifying impact: A better metric for measuring journalism&amp;#8221;, January 14, 2012. &lt;a href='http://www.greglinch.com/blog/2012/01/14/quantifying-impact-a-better-metric-for-measuring-journalism/'&gt;http://www.greglinch.com/blog/2012/01/14/quantifying-impact-a-better-metric-for-measuring-journalism/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br /&gt;
&lt;h3 id='can_i_add_something'&gt;Can I add something?&lt;/h3&gt;

&lt;p&gt;Sure! Just go &lt;a href='http://bit.ly/EditImpactBibliography'&gt;here&lt;/a&gt; and edit the document using &lt;a href='https://draftin.com/'&gt;Draft&lt;/a&gt; &amp;#8211; a great new tool for versioned writing. Once you add something, I&amp;#8217;ll update this website to reflect those changes.&lt;/p&gt;
&lt;br /&gt;
&lt;h3 id='this_format_is_ugly'&gt;This format is ugly!&lt;/h3&gt;

&lt;p&gt;I know, I&amp;#8217;m horrible at design. Feel free to take all these links and make something pretty and more useful!&lt;/p&gt;
&lt;br /&gt;
&lt;h1 id='impact_reading_list'&gt;Impact Reading List&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;Abelson, Brian, &amp;#8220;HI Score: Towards a new metric of influence,&amp;#8221; June 27, 2012. &lt;a href='http://harmony-institute.org/therippleeffect/2012/06/27/hi-score-towards-a-new-metric-of-influence/'&gt;http://harmony-institute.org/therippleeffect/2012/06/27/hi-score-towards-a-new-metric-of-influence/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ad Council, &amp;#8220;Overview of Ad Council research &amp;amp; evaluation procedures,&amp;#8221; Ad Council, Date Unknown. &lt;a href='http://www.adcouncil.org/Impact/Research/Overview-of-Ad-Council-Research-Evaluation-Procedures'&gt;http://www.adcouncil.org/Impact/Research/Overview-of-Ad-Council-Research-Evaluation-Procedures&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Anderson, C.W. et al, “Post-Industrial Journalism: Adapting to the Present,&amp;#8221; Tow Center, Fall 2012. &lt;a href='http://skollworldforum.org/debate-post/eyeballs-and-impact-are-we-measuring-the-right-things-if-we-care-about-social-progress/'&gt;http://towcenter.org/wp-content/uploads/2012/11/TOWCenter-Post_Industrial_Journalism.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Barrett, Diana and Leddy, Sheila, &amp;#8220;Assessing Creative Media&amp;#8217;s Social Impact&amp;#8221;, The Fledgling Fund, December 2008. &lt;a href='http://www.thefledglingfund.org/wp-content/uploads/2012/11/Impact-Paper.pdf'&gt;http://www.thefledglingfund.org/wp-content/uploads/2012/11/Impact-Paper.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Blakely, Johanna (Norman Lear Center), &amp;#8220;Research study finds that a film can have a measurable impact on audience behavior&amp;#8221;, February 22, 2012 &lt;a href='http://www.learcenter.org/pdf/FoodInc.pdf'&gt;http://www.learcenter.org/pdf/FoodInc.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Blakely, Johanna, &amp;#8220;TedX Phoenix &amp;#8211; Movies for a change&amp;#8221;, February 12, 2012. &lt;a href='http://youtu.be/Pb0FZPzzWuk'&gt;http://youtu.be/Pb0FZPzzWuk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bornstein, David, “Why we need solutions journalism,&amp;#8221; Skoll World Forum, 2012. &lt;a href='http://skollworldforum.org/debate-post/why-we-need-solutions-journalism/'&gt;http://skollworldforum.org/debate-post/why-we-need-solutions-journalism/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Brock, Andrea, et al./ Center for Effective Philanthropy, “Room for Improvement: Foundations’ Support of Nonprofit Performance Assessment,&amp;#8221; 2012 &lt;a href='http://www.effectivephilanthropy.org/assets/pdfs/Room%20for%20Improvement.pdf'&gt;http://www.effectivephilanthropy.org/assets/pdfs/Room%20for%20Improvement.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Caulkin, Simon, &amp;#8220;The rule is simple: Be careful what you measure&amp;#8221;, February 9, 2008. &lt;a href='http://www.guardian.co.uk/business/2008/feb/10/businesscomment1'&gt;http://www.guardian.co.uk/business/2008/feb/10/businesscomment1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Chinn, Dana et al., &amp;#8220;Measuring the online impact of your information project&amp;#8221;, Knight Foundation / FSG Social Impact Advisors, May 31, 2011. &lt;a href='http://www.knightfoundation.org/media/uploads/publication_pdfs/Measuring-the-Online-Impact-of-Information-Projects-092910-FINAL_1.pdf'&gt;http://www.knightfoundation.org/media/uploads/publication_pdfs/Measuring-the-Online-Impact-of-Information-Projects-092910-FINAL_1.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clark, Jessica, &amp;#8220;Find needs and five tools for measuring media impact,&amp;#8221; May 11, 2010. &lt;a href='http://www.pbs.org/mediashift/2010/05/5-needs-and-5-tools-for-measuring-media-impact131.html'&gt;http://www.pbs.org/mediashift/2010/05/5-needs-and-5-tools-for-measuring-media-impact131.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clark, Jessica and Van Slyke, Tracy, &amp;#8220;Investing in Impact&amp;#8221;, The Center for Social Media, May 12, 2010. &lt;a href='http://www.centerforsocialmedia.org/sites/default/files/documents/pages/Investing_in_Impact.pdf'&gt;http://www.centerforsocialmedia.org/sites/default/files/documents/pages/Investing_in_Impact.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clark, Jessica and Abrash, Barbara, &amp;#8220;Social justice documentary: Designing for impact,&amp;#8221; Center for Social Media, September 2011. &lt;a href='http://www.centerforsocialmedia.org/sites/default/files/documents/pages/designing_for_impact.pdf'&gt;http://www.centerforsocialmedia.org/sites/default/files/documents/pages/designing_for_impact.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Community Wealth Ventures, &amp;#8220;How nonprofit news ventures seek sustainability&amp;#8221;, Knight Foundation, October 2011. &lt;a href='http://www.knightfoundation.org/media/uploads/publication_pdfs/13664_KF_NPNews_Overview_10-17-2.pdf'&gt;http://www.knightfoundation.org/media/uploads/publication_pdfs/13664_KF_NPNews_Overview_10-17-2.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Channel 4 BritDoc Foundation, &amp;#8220;Evaluation&amp;#8221;, &lt;a href='http://britdoc.org/real_good/evaluation'&gt;http://britdoc.org/real_good/evaluation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Duros, Sally, &amp;#8220;Impact counts for hyperlocal news, but how to count it?&amp;#8221;, August 6, 2012. &lt;a href='http://www.blockbyblock.us/2012/08/06/impact-and-what-it-is-for-community-and-hyperlocal-news/'&gt;http://www.blockbyblock.us/2012/08/06/impact-and-what-it-is-for-community-and-hyperlocal-news/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Fisch, Shaolm M. and Truglio, Rosemarie T., &amp;#8220;G is for growing: Thirty years of research on children and Sesame Street,&amp;#8221; Children&amp;#8217;s Television Workshop, 2000. &lt;a href='http://www.amazon.com/Growing-Thirty-Research-Children-Communications/dp/0805833951'&gt;http://www.amazon.com/Growing-Thirty-Research-Children-Communications/dp/0805833951&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Fox, Steve, &amp;#8220;Why are we spending so much time ‘Measuring the Impact of Journalism?’&amp;#8221; March 30, 2012. &lt;a href='http://umassjournalismprofs.wordpress.com/2012/03/30/why-are-we-spending-so-much-time-measuring-the-impact-of-journalism/'&gt;http://umassjournalismprofs.wordpress.com/2012/03/30/why-are-we-spending-so-much-time-measuring-the-impact-of-journalism/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;FSG Social Impact Advisors/ John S. and James L. Knight Foundation, “Measuring the Online Impact of Your Information Project: A Primer for Practitioners and Funders,&amp;#8221; 2010. &lt;a href='http://www.effectivephilanthropy.org/assets/pdfs/Room%20for%20Improvement.pdf'&gt;http://www.fsg.org/tabid/191/ArticleId/428/Default.aspx?srpush=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;FSG Social Impact Advisors/ John S. and James L. Knight Foundation, &amp;#8220;IMPACT: A practical guide to evaluating community information projects,&amp;#8221; February 2011. &lt;a href='http://www.knightfoundation.org/media/uploads/publication_pdfs/Impact-a-guide-to-Evaluating_Community_Info_Projects.pdf'&gt;http://www.knightfoundation.org/media/uploads/publication_pdfs/Impact-a-guide-to-Evaluating_Community_Info_Projects.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Gates, Bill, &amp;#8220;My Plan to Fix The World&amp;#8217;s Biggest Problems&amp;#8221;, Wall Street Journal, January 25, 2013. &lt;a href='http://online.wsj.com/article/SB10001424127887323539804578261780648285770.html'&gt;http://online.wsj.com/article/SB10001424127887323539804578261780648285770.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Gates Foundation, “A Guide to Actionable Measurement,&amp;#8221; 2010. &lt;a href='http://www.effectivephilanthropy.org/assets/pdfs/Room%20for%20Improvement.pdf'&gt;http://www.gatesfoundation.org/learning/Documents/guide-to-actionable-measurement.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Gigli, Susan, &amp;#8220;What Is &amp;#8216;Disruptive Metrics&amp;#8217;&amp;#8220;, March 20, 2013. &lt;a href='http://www.intermedia.org/2013/03/20/what-is-disruptive-metrics/'&gt;http://www.intermedia.org/2013/03/20/what-is-disruptive-metrics/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Gill, Kathy E., &amp;#8220;Carnival of Journalism: How To Measure What Matters?&amp;#8221;, April 4, 2012. &lt;a href='http://wiredpen.com/2012/04/04/carnival-of-journalism-how-to-measure-what-matters/'&gt;http://wiredpen.com/2012/04/04/carnival-of-journalism-how-to-measure-what-matters/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Gordon, John, &amp;#8220;See, say, feel, do: Social media metrics that matter,&amp;#8221; Fenton, Date Unknown. &lt;a href='http://www.fenton.com/resources/see-say-feel-do/'&gt;http://www.fenton.com/resources/see-say-feel-do/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Graves, Lucas, &amp;#8220;Traffic Jam: We’ll never agree about online audience size,&amp;#8221; September 7, 2010. &lt;a href='http://www.cjr.org/reports/traffic_jam.php?page=all'&gt;http://www.cjr.org/reports/traffic_jam.php?page=all&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Graves, Lucas et al., &amp;#8220;Confusion online: Faulty metrics and the future of digital journalism,&amp;#8221; Tow Center, September, 2010. &lt;a href='http://brianabelson.com/assets/impact_papers/faulty_metrics.pdf'&gt;http://brianabelson.com/assets/impact_papers/faulty_metrics.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Green, Daniel, “Eyeballs and Impact: Are we measuring the right things if we care about social progress?,&amp;#8221; Skoll World Forum, 2012. &lt;a href='http://skollworldforum.org/debate-post/eyeballs-and-impact-are-we-measuring-the-right-things-if-we-care-about-social-progress/'&gt;http://skollworldforum.org/debate-post/eyeballs-and-impact-are-we-measuring-the-right-things-if-we-care-about-social-progress/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Harmony Institute, &amp;#8220;Waiting for Superman: Entertainment evaluation highlights&amp;#8221;, Harmony Institute, May 2011. &lt;a href='http://harmony-institute.org/wp-content/uploads/2011/07/WFS_Highlights_20110701.pdf'&gt;http://harmony-institute.org/wp-content/uploads/2011/07/WFS_Highlights_20110701.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Heedy, Lucy and Keen, Sara, &amp;#8220;SROI for funders,&amp;#8221; New Philanthropy Capital, September 2010. &lt;a href='http://www.thinknpc.org/?attachment_id=815&amp;amp;post-parent=4924'&gt;http://www.thinknpc.org/?attachment_id=815&amp;amp;post-parent=4924&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hickman, Blair et al., &amp;#8220;Best of MuckReads 2012&amp;#8221;, ProPublica, December 31, 2012. &lt;a href='http://www.propublica.org/article/best-of-muckreads-2012'&gt;http://www.propublica.org/article/best-of-muckreads-2012&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;International Center For Journalists, &amp;#8220;An evaluation of the Knight International Journalism Fellowships&amp;#8221;, ICFJ, Date Unknown. &lt;a href='http://www.knightfoundation.org/media/uploads/publication_pdfs/Evaluation_of_Knight_ICFJ_Fellowships_final.pdf'&gt;http://www.knightfoundation.org/media/uploads/publication_pdfs/Evaluation_of_Knight_ICFJ_Fellowships_final.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;International Center For Journalists, &amp;#8220;Evaluation field manual and tools for the Knight International Journalism Fellowships&amp;#8221;, ICFJ, January 2011. &lt;a href='http://issuu.com/kijf/docs/icfj_knight_international_evaluation_manual'&gt;http://issuu.com/kijf/docs/icfj_knight_international_evaluation_manual&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Johnson, John, &amp;#8220;A New Approach to Making Films That Matter,&amp;#8221; January 11, 2013. &lt;a href='http://www.infomart.com/2012/10/17/un-juking-the-stats-measuring-journalisms-impact-on-society/'&gt;http://www.good.is/posts/a-new-approach-to-making-films-that-matter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Karlan, Dean et al., &amp;#8220;More than good intentions: How a new economics is helping to solve global poverty&amp;#8221;, Dutton, 2011. &lt;a href='http://www.amazon.com/More-Than-Good-Intentions-Economics/dp/052595189X'&gt;http://www.amazon.com/More-Than-Good-Intentions-Economics/dp/052595189X&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;KETC, &amp;#8220;Facing the mortgage crisis: People, connections, resources&amp;#8221;, Spring 2008. &lt;a href='https://mediaengage.adobeconnect.com/_a938034862/p90449908/'&gt;https://mediaengage.adobeconnect.com/_a938034862/p90449908/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kohavi, Ron, et al., &amp;#8220;Trustworthy online controlled experiments: Five puzzling outcomes explained&amp;#8221;, Microsoft, 2012. &lt;a href='http://www.exp-platform.com/Documents/puzzlingOutcomesInControlledExperiments.pdf'&gt;http://www.exp-platform.com/Documents/puzzlingOutcomesInControlledExperiments.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kramer, Mark and Kania, John, &amp;#8220;Collective Impact&amp;#8221;, Stanford Social Innovation Review, Winter 2011. &lt;a href='http://www.fsg.org/tabid/191/ArticleId/211/Default.aspx?srpush=true'&gt;http://www.fsg.org/tabid/191/ArticleId/211/Default.aspx?srpush=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kristof, Nicoholas D., &amp;#8220;Getting smart on aid,&amp;#8221; May 18, 2011. &lt;a href='http://www.nytimes.com/2011/05/19/opinion/19kristof.html?_r=1&amp;amp;partner=rssnyt&amp;amp;emc=rss'&gt;http://www.nytimes.com/2011/05/19/opinion/19kristof.html?_r=1&amp;amp;partner=rssnyt&amp;amp;emc=rss&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;King, Gary et al., &amp;#8220;Matching as nonparametric preprocessing for reducing model dependence in parametric causal inference,&amp;#8221; Political Analysis 15:199–236, 2007. &lt;a href='http://gking.harvard.edu/files/gking/files/matchp.pdf'&gt;http://gking.harvard.edu/files/gking/files/matchp.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Linch, Greg, &amp;#8220;Quantifying impact: A better metric for measuring journalism&amp;#8221;, January 14, 2012. &lt;a href='http://www.greglinch.com/blog/2012/01/14/quantifying-impact-a-better-metric-for-measuring-journalism/'&gt;http://www.greglinch.com/blog/2012/01/14/quantifying-impact-a-better-metric-for-measuring-journalism/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;LFA Group: Learning for Action / Bill &amp;amp; Melinda Gates Foundation / John S. and James L. Knight Foundation, “Deepening Engagement for Lasting Impact: Measuring Media Performance and Results,&amp;#8221; Februrary, 2013. (Forthcoming)&lt;/p&gt;

&lt;p&gt;Los Angeles Times Data Desk, &amp;#8220;Complete guide to the LAFD data controversy&amp;#8221;, Los Angeles Times, April 12, 2012 (Ongoing). &lt;a href='http://timelines.latimes.com/lafd-data-controversy/'&gt;http://timelines.latimes.com/lafd-data-controversy/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Mayer, Joy and Stern, Ruben, &amp;#8220;A resource for newsrooms: Identifying and measuring audience engagement efforts&amp;#8221; June 3, 2011, &lt;a href='http://www.rjionline.org/sites/default/files/theengagementmetric-fullreport-spring2011.pdf'&gt;http://www.rjionline.org/sites/default/files/theengagementmetric-fullreport-spring2011.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;McKinsey &amp;amp; Company, &amp;#8220;Learning for Social Impact&amp;#8221;, &lt;a href='http://lsi.mckinsey.com/'&gt;http://lsi.mckinsey.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;National Center for Media Engagement (NCME), &amp;#8220;Measuring Public Media&amp;#8217;s Impact: Challenges and Opportunities&amp;#8221;, March 2013. &lt;a href='http://mediaengage.org/CommunicateImpact/measure3.cfm'&gt;http://mediaengage.org/CommunicateImpact/measure3.cfm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ní Ógáin, Eibhlín et al., &amp;#8220;Making an impact: Impact measurement among charities and social enterprises in the UK&amp;#8221;, New Philanthropy Capital, October 2012. &lt;a href='http://www.thinknpc.org/publications/making-an-impact/making-an-impact/'&gt;http://www.thinknpc.org/publications/making-an-impact/making-an-impact/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Peters, Jeremy W., &amp;#8220;Some Newspapers, Tracking Readers Online, Shift Coverage&amp;#8221;, The New York Times, September 5, 2010. &lt;a href='http://www.nytimes.com/2010/09/06/business/media/06track.html'&gt;http://www.nytimes.com/2010/09/06/business/media/06track.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Peters, Jeremy W., &amp;#8220;A Newspaper, and a Legacy, Reordered&amp;#8221;, February 11, 2012 &lt;a href='http://www.nytimes.com/2012/02/12/business/media/the-washington-post-recast-for-a-digital-future.html?pagewanted=all&amp;amp;_r=0'&gt;http://www.nytimes.com/2012/02/12/business/media/the-washington-post-recast-for-a-digital-future.html?pagewanted=all&amp;amp;_r=0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Pilhofer, Aron, &amp;#8220;Find the right metric for news&amp;#8221;, July 25, 2012. &lt;a href='http://aronpilhofer.com/post/27993980039/the-right-metric-for-news'&gt;http://aronpilhofer.com/post/27993980039/the-right-metric-for-news&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Priem, Jason et al., “The Altmetrics Collection&amp;#8221;, Public Library of Science, 2012. &lt;a href='http://www.ploscollections.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0048753'&gt;http://www.ploscollections.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0048753&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ramsay, Clay et al., &amp;#8220;Misinformation and the 2010 Election: A Study of the US Electorate,&amp;#8221; December 10, 2010. &lt;a href='http://www.worldpublicopinion.org/pipa/pdf/dec10/Misinformation_Dec10_rpt.pdf'&gt;http://www.worldpublicopinion.org/pipa/pdf/dec10/Misinformation_Dec10_rpt.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Reisman, Jane et al., &amp;#8220;A handbook of data collection tools: Companion to &amp;#8216;A guide to measuring advocacy and policy&amp;#8217;&amp;#8220;, Organizational Research Services, 2007. &lt;a href='http://www.organizationalresearch.com/publicationsandresources/a_handbook_of_data_collection_tools.pdf'&gt;http://www.organizationalresearch.com/publicationsandresources/a_handbook_of_data_collection_tools.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Richardson, Breeze, “Measuring community engagement: A case study from Chicago Public Media,&amp;#8221; Reynolds Journalism Institute, December 1, 2011. &lt;a href='http://www.rjionline.org/blog/measuring-community-engagement-case-study-chicago-public-media'&gt;http://www.rjionline.org/blog/measuring-community-engagement-case-study-chicago-public-media&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Rosenblum, Michael, &amp;#8220;How to Quantify the Impact of Journalism,&amp;#8221; March 30, 2012. &lt;a href='http://www.nyvs.com/blog/user/michael/How-To-Quantify-The-Impact-of-Journalism'&gt;http://www.nyvs.com/blog/user/michael/How-To-Quantify-The-Impact-of-Journalism&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Salagnik, Matthew J. et al., &amp;#8220;Experimental study of inequality and unpredictability in an artificial cultural market&amp;#8221; Science 311, 854, 2006.&lt;a href='http://brianabelson.com/assets/impact_papers/SalagnikWatts2006.pdf'&gt;http://brianabelson.com/assets/impact_papers/SalagnikWatts2006.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Search, Jess, &amp;#8220;Beyond the box office: New docuemntary valuations,&amp;#8221; Channel 4 BritDoc Foundation, May 2011. &lt;a href='http://www.documentary.org/images/news/2011/AnInconvenientTruth_BeyondTheBoxOffice.pdf'&gt;http://www.documentary.org/images/news/2011/AnInconvenientTruth_BeyondTheBoxOffice.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sparkwise: &lt;a href='http://sparkwi.se/'&gt;http://sparkwi.se/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Spittle, Andrew, &amp;#8220;Defining new metrics for journalism,&amp;#8221; April 28, 2012. &lt;a href='http://www.infomart.com/2012/10/17/un-juking-the-stats-measuring-journalisms-impact-on-society/'&gt;http://andrewspittle.net/2012/04/28/new-metrics/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Stray, Jonathan, &amp;#8220;By the numbers, American journalism failed to inform voters,&amp;#8221; December 29, 2010. &lt;a href='http://jonathanstray.com/american-journalism-failed-to-inform-voters'&gt;http://jonathanstray.com/american-journalism-failed-to-inform-voters&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Stray, Jonathan, &amp;#8220;Designing journalism to be used,&amp;#8221; September 26, 2010. &lt;a href='http://jonathanstray.com/designing-journalism-to-be-used'&gt;http://jonathanstray.com/designing-journalism-to-be-used&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Stray, Jonathan, &amp;#8220;Does Journalism Work?,&amp;#8221; December 14, 2010. &lt;a href='http://jonathanstray.com/does-journalism-work'&gt;http://jonathanstray.com/does-journalism-work&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Stray, Jonathan, “Metrics, metrics everywhere: How do we measure the impact of journalism?,&amp;#8221; Nieman Journalism Lab, August 17, 2012. &lt;a href='http://www.niemanlab.org/2012/08/metrics-metrics-everywhere-how-do-we-measure-the-impact-of-journalism/'&gt;http://www.niemanlab.org/2012/08/metrics-metrics-everywhere-how-do-we-measure-the-impact-of-journalism/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Stuart, E.A., &amp;#8220;Matching methods for causal inference: A review and a look forward,&amp;#8221; Statistical Science 25(1): 1-21, 2010. &lt;a href='http://biostat.jhsph.edu/~estuart/Stuart10.StatSci.pdf'&gt;http://biostat.jhsph.edu/~estuart/Stuart10.StatSci.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tofel, Richard J., &amp;#8220;Non-profit journalism &amp;#8211; Issues around impact: A white paper from ProPublica,&amp;#8221; February, 2013. &lt;a href='http://s3.amazonaws.com/propublica/assets/about/LFA_ProPublica-white-paper_2.1.pdf'&gt;http://s3.amazonaws.com/propublica/assets/about/LFA_ProPublica-white-paper_2.1.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;TRASI: Tools and Resources for Assessing Social Impact: &lt;a href='http://trasicommunity.ning.com/'&gt;http://trasicommunity.ning.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ward, Nicholas/ Infomart, “Un-juking the stats: Measuring journalism’s impact on society,&amp;#8221; October 17, 2012. &lt;a href='http://www.infomart.com/2012/10/17/un-juking-the-stats-measuring-journalisms-impact-on-society/'&gt;http://www.infomart.com/2012/10/17/un-juking-the-stats-measuring-journalisms-impact-on-society/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ward, Nicholas/ Infomart, “We become what we measure: Developing impact metrics for journalism,&amp;#8221; October 3, 2012. &lt;a href='http://www.infomart.com/2012/10/17/un-juking-the-stats-measuring-journalisms-impact-on-society/'&gt;http://www.infomart.com/2012/10/03/we-become-what-we-measure-developing-impact-metrics-for-journalism/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;White, John Myles, &amp;#8220;Bandit Algorithms for Website Optimization: Developing, Deploying, and Debugging&amp;#8221;, O&amp;#8217;Reilly Media, 2012. &lt;a href='http://oreilly.com/shop/product/0636920027393.html?bB=g'&gt;http://oreilly.com/shop/product/0636920027393.html?bB=g&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WITNESS, &amp;#8220;WITNESS performance dashboard,&amp;#8221; WITNESS, December 2009. &lt;a href='http://www.witness.org/sites/default/files/downloads/witness-dashboard-evaluation-2010.pdf'&gt;http://www.witness.org/sites/default/files/downloads/witness-dashboard-evaluation-2010.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Zuckerman, Ethan, “Metrics for civic impacts of journalism,&amp;#8221; June 30, 2011. &lt;a href='http://www.infomart.com/2012/10/17/un-juking-the-stats-measuring-journalisms-impact-on-society/'&gt;http://www.ethanzuckerman.com/blog/2011/06/30/metrics-for-civic-impacts-of-journalism/&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;</description>
				<pubDate>Tue, 02 Apr 2013 00:00:00 -0400</pubDate>
				<link>http://brianabelson.com/open-news/2013/04/02/Impact-Bibliography.html</link>
				<guid isPermaLink="true">http://brianabelson.com/open-news/2013/04/02/Impact-Bibliography.html</guid>
			</item>
		
			<item>
				<title>Creating a metric for news apps</title>
				<description>&lt;p&gt;More and more, newsrooms large and small are adopting digital and data-driven techniques to engage readers with their work. &lt;a href='http://www.propublica.org/nerds/item/knight-foundation-makes-grant-to-support-propublicas-news-applications-desk'&gt;News applications&lt;/a&gt;, or &amp;#8220;large web-based interactive database&lt;span&gt;s&lt;/span&gt; that tell a journalistic story using software instead of words and pictures&amp;#8221;, have emerged as the standard medium through which journalists present the outcomes of data-driven projects. From &lt;a href='http://projects.propublica.org/docdollars/'&gt;Dollars for Docs&lt;/a&gt; to &lt;a href='http://project.wnyc.org/dogs-of-nyc/'&gt;Dogs of NYC&lt;/a&gt;, news apps present readers with interactive experiences that offer them opportunities to engage more deeply with a story than traditional article-based formats. Given the common structure of news apps (discussed below) and the existence of &lt;a href='https://developers.google.com/analytics/devguides/collection/gajs/eventTrackerGuide'&gt;well-developed tools&lt;/a&gt; for tracking user-level events on a website, I propose a simple framework for measuring engagement with news applications. &lt;br /&gt;&lt;/p&gt;

&lt;h3 id='what_makes_a_news_app_successful'&gt;What makes a news app &amp;#8220;successful&amp;#8221;?&lt;/h3&gt;

&lt;p&gt;In a recent &lt;a href='http://www.insidethunderdome.com/'&gt;InsideThunderdome&lt;/a&gt; live chat, &lt;a href='https://twitter.com/kleinmatic'&gt;Scott Klein&lt;/a&gt;, editor of News Applications at ProPublica, wrote, &amp;#8220;what I like to see in a news application &lt;span&gt;is&lt;/span&gt; a way to see the &amp;#8220;far&amp;#8221; view (in other words, the big national picture) and the &amp;#8220;near&amp;#8221; view (how the big national phenomenon relates to me personally).&amp;#8221; Put another way, the &lt;em&gt;far view&lt;/em&gt; &amp;#8220;lets you know why you should care, what the story is, what the national phenomenon is and how places compare to each other.&amp;#8221; The &lt;em&gt;near view&lt;/em&gt;, on the other hand, walks you &amp;#8220;through levels of abstraction down to the very specific &amp;#8211; your town, your street, your school. So if we&amp;#8217;re successful now you know the national picture, why you should care, and what it&amp;#8217;s got to do with you.&amp;#8221;&lt;/p&gt;

&lt;p&gt;Echoing this philosophy, &lt;a href='http://www.twitter.com/mhkeller'&gt;Michael Keller&lt;/a&gt;, Senior Data Reporter at Daily Beast says, &amp;#8220;we think of interactives as tools to help people to see how a story might matter to them. Here, &amp;#8216;success&amp;#8217; means drawing people into the story and, if we&amp;#8217;re lucky, also building in ways to hear how it affected them.&amp;#8221;&lt;/p&gt;

&lt;p&gt;Other indications of what makes a &amp;#8220;successful&amp;#8221; news app come through job ads. For instance, &lt;a href='http://www.pbs.org/newshour/jobs/webdev.html'&gt;PBS&amp;#8217;s News Hour&lt;/a&gt; is looking for someone to &amp;#8220;develop news applications that allow users to explore the stories behind data.&amp;#8221;&lt;/p&gt;

&lt;p&gt;From these examples, a pattern emerges: a &amp;#8220;successful&amp;#8221; news application is one that presents a reader with a story and offers them an opportunity to dig deeper. Given this common structure of news applications, it should be possible to create a simple metric that captures the degree to which readers use an app to move from the far view to the near view. Such a metric might help newsrooms begin to assess readers&amp;#8217; level of engagement; defined here as the intersection of what readers want and what newsrooms want readers to do. &lt;br /&gt;&lt;/p&gt;

&lt;h3 id='how_might_we_measure_this'&gt;How might we measure this?&lt;/h3&gt;

&lt;p&gt;Over the past couple of years, &lt;a href='http://www.niemanlab.org/2012/08/metrics-metrics-everywhere-how-do-we-measure-the-impact-of-journalism/'&gt;journalists&lt;/a&gt;, &lt;a href='http://aronpilhofer.com/post/27993980039/the-right-metric-for-news'&gt;editors&lt;/a&gt;, and &lt;a href='http://www.greglinch.com/2012/01/quantifying-impact-a-better-metric-for-measuring-journalism.html'&gt;news room developers&lt;/a&gt; have begun to openly criticize the poverty of traditional metrics like page views and average time spent on page. Most of their frustration lies in the inability of these metrics to capture deeper ideas like attitudinal, behavioral, or legislative change - in a word: impact. But while automated metrics may never fully capture these important considerations, they could help us get at some idea of overall reader engagement with a news application. &lt;br /&gt;&lt;/p&gt;

&lt;h5 id='event_tracking'&gt;Event tracking&lt;/h5&gt;

&lt;p&gt;One step past page-views and time spent on page are more granular web metrics that capture individual events. From Google Analytics, Omniture, to WebTrends, many free and paid-for analytics services offer access to raw event-level data, or individual actions taken on a given page. &amp;#8220;Events&amp;#8221; can be created with small tags in your site&amp;#8217;s JavaScript (&lt;a href='https://developers.google.com/analytics/devguides/collection/gajs/eventTrackerGuide'&gt;see how to do this with Google Analytics&lt;/a&gt;). By tagging elements of a project associated with clicking through a site, entering a search term, watching a video, or sharing on social media, event tracking can be used to track a users path from the &amp;#8216;far&amp;#8217; to the &amp;#8216;near&amp;#8217; of news apps. &lt;br /&gt;&lt;/p&gt;

&lt;h5 id='identifying_users'&gt;Identifying users&lt;/h5&gt;

&lt;p&gt;The difficult (&lt;a href='http://en.wikipedia.org/wiki/Internet_privacy'&gt;and perhaps troubling&lt;/a&gt;) aspect of event tracking is the necessity of identifying individual users of a site. The New York Times is lucky enough to have substantial traffic from registered users. In these cases, collecting user-level event data over time and across multiple devices is simplified through logins. However, IP addresses or IDs extracted from &lt;a href='http://en.wikipedia.org/wiki/HTTP_cookie'&gt;cookies&lt;/a&gt;, small bits of information that sites use to track their users, can serve as proxies. While these can be deactivated on &lt;a href='http://www.aboutcookies.org/default.aspx?page=1'&gt;most modern browsers&lt;/a&gt;, or through services like &lt;a href='https://www.torproject.org/'&gt;Tor&lt;/a&gt;, in most cases they can represent an &amp;#8220;individual user.&amp;#8221; In turn, reconciling this information allows us to study the scope of each user&amp;#8217;s interaction with an app. &lt;br /&gt;&lt;/p&gt;

&lt;h3 id='a_case_study_the_red_carpet_project'&gt;A case study: &lt;em&gt;The Red Carpet Project&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;In late January, the New York Times interactive team released &lt;a href='http://www.nytimes.com/projects/oscars/red-carpet-history/'&gt;an app&lt;/a&gt; for exploring 15 years of outfits on the Red Carpet. The app represents a new take on the slide show, enabling filtering, searching, and sharing of certain slices of slides. Built into the app is an implicit logic of engagement: while the images are on showcase, readers are encouraged to explore the dresses and suits curated by editors and filter the images by time, style, and color. If all goes well, the readers share their own selection of outfits on social media. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h5 id='tagging_news_apps'&gt;Tagging news apps&lt;/h5&gt;
&lt;br /&gt;&lt;br /&gt;&lt;img src='/img/posts/metric-for-news-apps/red_carpet_site.png' /&gt;&lt;br /&gt;&lt;br /&gt;
&lt;p&gt;In &lt;em&gt;&lt;a href='http://www.nytimes.com/projects/oscars/red-carpet-history/'&gt;The Red Carpet Project&lt;/a&gt;&lt;/em&gt;, the far view are the images themselves - what the app would have been had it been merely a slide show. Readers move closer to the near view as they filter the outfits, explore the editors&amp;#8217; selections, and share the site on social media. By tagging each of these events with unique ids, we can isolate users whose behavior on the site was most indicative of &amp;#8220;engagement.&amp;#8221; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h5 id='exploring_the_data'&gt;Exploring the data&lt;/h5&gt;
&lt;br /&gt;&lt;br /&gt;&lt;center&gt;
    &lt;img src='/img/posts/metric-for-news-apps/number_of_events.png' /&gt;
&lt;/center&gt;&lt;br /&gt;
&lt;p&gt;Given the data for these events, we can now measure the most-used elements of the app. In the figure above, we group events into simpler categories. Note that &amp;#8220;faves&amp;#8221; connote instances where users selected their favorite outfits without necessarily sharing them on social media. We find that over 95% of the events captured were associated with viewing an image - the &amp;#8220;far view.&amp;#8221; However, without knowing the degree to which each reader used all possible features, we cannot approximate levels of engagement. &lt;br /&gt; &lt;br /&gt; &lt;center&gt;
    &lt;img src='/img/posts/metric-for-news-apps/number_of_features_used.png' /&gt;
&lt;/center&gt; &lt;br /&gt; By counting the number of unique features each reader used, we get a better idea of the degree to which users explored the app&amp;#8217;s near view. We immediately see that readers rarely engaged with more than one or two of the apps features. Taken together these two graphs beg the question: what was the difference between readers who only viewed slides and those who used additional features? &lt;br /&gt; &lt;br /&gt; &lt;center&gt;
    &lt;img src='/img/posts/metric-for-news-apps/time_v_events.png' /&gt;
&lt;/center&gt; &lt;br /&gt; In this view, we see that more than half of the users viewed only slides and 5% clicked every slide without engaging other features. Readers that only clicked on slides also spent less time on the page than readers that explored more of the site. While such readers may have used the app extensively, they didn&amp;#8217;t reach its &amp;#8220;near view.&amp;#8221; In creating a metric for news apps, we should account for these cases, assigning penalties for behaviors that suggest a lack of engagement. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h5 id='creating_a_metric_of_engagement'&gt;Creating a metric of engagement&lt;/h5&gt;

&lt;p&gt;With these insights, we begin to get a sense of the things we can measure to approximate a user&amp;#8217;s overall engagement with the app. While we&amp;#8217;d like to give weight to the raw number of events &amp;#8211; after all, rapidly clicking through 500 images without filtering is its own form of engagement &amp;#8211; we also want to assign influence to features that capture whether a user reached the app&amp;#8217;s near view. A metric of engagement for this app might looking something like this: &lt;br /&gt; &lt;br /&gt; &lt;center&gt;
    &lt;img src='/img/posts/metric-for-news-apps/engagement.png' /&gt;
&lt;/center&gt; &lt;br /&gt; &lt;br /&gt; While I&amp;#8217;ve simplified the math here &amp;#8211; the variables are also transformed to decrease the influence of outliers and re-scaled to increase interpretability &amp;#8211; the abstracted equation represents a simplified measurement which captures the logic of engagement embedded in the site. In this case, the corresponding density plot reveals a bifurcated distribution of user experiences, with one half barely engaging with the site (1-20), and the other half dispersed over a long-tail (20-100). However, we might imagine alternate situations where more/less users explored the deeper intricacies of the app. In these cases we would expect the distribution of engagement to look much different. &lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h3 id='what_might_we_do_with_this'&gt;What might we do with this?&lt;/h3&gt;

&lt;p&gt;Metrics, while abstractions, are useful in that they provide a single number one can use to track progress. As &lt;a href='http://online.wsj.com/article/SB10001424127887323539804578261780648285770.html'&gt;Bill Gates wrote&lt;/a&gt; in a recent &lt;em&gt;Wall Street Journal&lt;/em&gt; article (while referencing William Rosen&amp;#8217;s &lt;em&gt;&lt;a href='http://www.amazon.com/Most-Powerful-Idea-World-Invention/dp/0226726347'&gt;The Most Powerful Idea in the World&lt;/a&gt;&lt;/em&gt;), &amp;#8220;Without feedback from precise measurement &amp;#8230; invention is &amp;#8216;doomed to be rare and erratic.&amp;#8217; With it, invention becomes &amp;#8216;commonplace.&amp;#8217;&amp;#8221; Without a metric for news apps, our only tools for gauging success will be conjecture and anecdote - a great irony given the meticulousness with which data is cleaned and analyzed to construct these projects. With a standard, interpretable metric, editors and journalists can begin to judge whether their intuitions match up with their readers behavior; analysts can compare apps over time and across news organizations; developers will come to value simplicity of presentation and ease of use over technical complexity; and, perhaps most importantly, news organizations will begin designing their digital offerings with &lt;a href='http://jonathanstray.com/designing-journalism-to-be-used'&gt;users in mind&lt;/a&gt;. While the measurements proposed here are just a rough sketch, I hope they will lead to an open discussion on the development of meaningul metrics for journalism.&lt;/p&gt;</description>
				<pubDate>Mon, 18 Mar 2013 00:00:00 -0400</pubDate>
				<link>http://brianabelson.com/open-news/2013/03/18/A-Metric-For-News-Apps.html</link>
				<guid isPermaLink="true">http://brianabelson.com/open-news/2013/03/18/A-Metric-For-News-Apps.html</guid>
			</item>
		
			<item>
				<title>Using spam bots for live reporting</title>
				<description>&lt;p&gt;For an upcoming project for &lt;a href='http://newsbeastlabs.tumblr.com/'&gt;NewsBeastLabs&lt;/a&gt; on the gun debate, I’ve been monitoring statements representatives have made on the topic. As President Obama prepared to unveil his proposal for gun control last Wednesday, &lt;a href='http://www.twitter.com/mhkeller'&gt;Michael Keller&lt;/a&gt; and I were curious to see the reactions of representatives to the highly publicized announcement. Given the degree to which breaking news is now reported (and responded to) on social media, we thought it would be useful to build a bot to log officials’ comments on certain issues and present them in real-time. Such a tool could be used by news rooms to engage their readers on a continuous basis by aggregating and serving content from members of particular communities or who serve on different committees.&lt;/p&gt;

&lt;h3 id='repsguntweets_was_born'&gt;&lt;a href='http://www.twitter.com/repsguntweets'&gt;@RepsGunTweets&lt;/a&gt; was born.&lt;/h3&gt;

&lt;p&gt;We were inspired by the work of 2013 Mozilla-Knight OpenNews fellows who recently built a prototpe for an app called “if (this) then news,&amp;#8221; a news-oriented take on IFTTT – a site for linking triggers from gmail, twitter, dropbox, and other services to actions on the web. Applying this logic to news coverage, the fellows created the shell for a tool that would monitor live data streams, detect important events, and issue notifications. As Vice President Biden took the mic, we started furiously coding up a bot that would follow the twitter accounts of US Representatives and retweet any comment that included “gun&amp;#8221;, “assault weapon&amp;#8221;, “firearm&amp;#8221;, or other relvant keywords. After a couple hours of missteps and headaches, we eventually got @RepsGunTweets up and running. In the last ten days, the bot has logged 307 tweets; two-thirds of which came in the first three days. We’re still analyzing the conversation but one interesting observation is representatives who are not in favor of gun control tend to link to longer explanations of their position on their website instead of tweet a comment.&lt;/p&gt;

&lt;h3 id='under_the_hood'&gt;Under the hood&lt;/h3&gt;

&lt;p&gt;At its core a retweet bot is a pretty simple tool: Follow a feed, find what matters, and serve it back up under a single account. The harder part is figuring out how to accurately communicate with Twitter’s API. Using tweepy for python we were able to easily access twitter’s numerous methods. All we needed to provide it with were the the consumer key, consumer secret, access token, and access token secret for an application generated on http://dev.twitter.com/apps). The bot follows CSPAN’s member of congress list and applies a regular expression for the desired keywords and retweets any matches.For even more technical info, including an easy way to create your own retweet bot, check out &lt;a href='http://www.github.com/abelsonlive/regextweet'&gt;this Github page&lt;/a&gt;.&lt;/p&gt;</description>
				<pubDate>Tue, 29 Jan 2013 00:00:00 -0500</pubDate>
				<link>http://brianabelson.com/open-news/2013/01/29/RegexTweet.html</link>
				<guid isPermaLink="true">http://brianabelson.com/open-news/2013/01/29/RegexTweet.html</guid>
			</item>
		
	</channel>
</rss>
